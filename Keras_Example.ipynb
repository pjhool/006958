{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjhool/Keras-Deep-Learning-Example/blob/master/Keras_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eFHYvSpAKfUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36479
        },
        "outputId": "f38d7b37-1a40-4cc1-d551-b9b65b49a6d8"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "# 1. 데이터셋 준비하기\n",
        "\n",
        "# 훈련셋과 시험셋 로딩\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# 훈련셋과 검증셋 분리\n",
        "X_val = X_train[50000:]\n",
        "Y_val = Y_train[50000:]\n",
        "X_train = X_train[:50000]\n",
        "Y_train = Y_train[:50000]\n",
        "\n",
        "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
        "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "\n",
        "# 훈련셋, 검증셋 고르기\n",
        "train_rand_idxs = np.random.choice(50000, 700)\n",
        "val_rand_idxs = np.random.choice(10000, 300)\n",
        "\n",
        "X_train = X_train[train_rand_idxs]\n",
        "Y_train = Y_train[train_rand_idxs]\n",
        "X_val = X_val[val_rand_idxs]\n",
        "Y_val = Y_val[val_rand_idxs]\n",
        "\n",
        "# 라벨링 전환\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_val = np_utils.to_categorical(Y_val)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# 3. 모델 엮기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
        "\n",
        "# 5. 모델 학습 과정 표시하기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 700 samples, validate on 300 samples\n",
            "Epoch 1/1000\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
            "Epoch 2/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
            "Epoch 3/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
            "Epoch 4/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
            "Epoch 5/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
            "Epoch 6/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
            "Epoch 7/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
            "Epoch 8/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
            "Epoch 9/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
            "Epoch 10/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
            "Epoch 11/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
            "Epoch 12/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
            "Epoch 13/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
            "Epoch 14/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
            "Epoch 15/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
            "Epoch 16/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
            "Epoch 17/1000\n",
            "700/700 [==============================] - 0s 477us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
            "Epoch 18/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
            "Epoch 19/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
            "Epoch 20/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
            "Epoch 21/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
            "Epoch 22/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
            "Epoch 23/1000\n",
            "700/700 [==============================] - 0s 485us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
            "Epoch 24/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
            "Epoch 25/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
            "Epoch 26/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
            "Epoch 27/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
            "Epoch 28/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
            "Epoch 29/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
            "Epoch 30/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
            "Epoch 31/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
            "Epoch 32/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
            "Epoch 33/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
            "Epoch 34/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
            "Epoch 35/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
            "Epoch 36/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
            "Epoch 37/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
            "Epoch 38/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
            "Epoch 39/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
            "Epoch 40/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
            "Epoch 41/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
            "Epoch 42/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
            "Epoch 43/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
            "Epoch 44/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
            "Epoch 45/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
            "Epoch 46/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
            "Epoch 47/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
            "Epoch 48/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
            "Epoch 49/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
            "Epoch 50/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
            "Epoch 51/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
            "Epoch 52/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
            "Epoch 53/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
            "Epoch 54/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
            "Epoch 55/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
            "Epoch 56/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
            "Epoch 57/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
            "Epoch 58/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
            "Epoch 59/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
            "Epoch 60/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
            "Epoch 61/1000\n",
            "700/700 [==============================] - 0s 392us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
            "Epoch 62/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
            "Epoch 63/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
            "Epoch 64/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
            "Epoch 65/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
            "Epoch 66/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
            "Epoch 67/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
            "Epoch 68/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
            "Epoch 69/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
            "Epoch 70/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
            "Epoch 71/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
            "Epoch 72/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
            "Epoch 73/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
            "Epoch 74/1000\n",
            "700/700 [==============================] - 0s 477us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
            "Epoch 75/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
            "Epoch 76/1000\n",
            "700/700 [==============================] - 0s 490us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
            "Epoch 77/1000\n",
            "700/700 [==============================] - 0s 492us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
            "Epoch 78/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
            "Epoch 79/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
            "Epoch 80/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
            "Epoch 81/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
            "Epoch 82/1000\n",
            "700/700 [==============================] - 0s 483us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
            "Epoch 83/1000\n",
            "700/700 [==============================] - 0s 484us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
            "Epoch 84/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
            "Epoch 85/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
            "Epoch 86/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
            "Epoch 87/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
            "Epoch 88/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
            "Epoch 89/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
            "Epoch 90/1000\n",
            "700/700 [==============================] - 0s 504us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
            "Epoch 91/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
            "Epoch 92/1000\n",
            "700/700 [==============================] - 0s 499us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
            "Epoch 93/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
            "Epoch 94/1000\n",
            "700/700 [==============================] - 0s 492us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
            "Epoch 95/1000\n",
            "700/700 [==============================] - 0s 471us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
            "Epoch 96/1000\n",
            "700/700 [==============================] - 0s 538us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
            "Epoch 97/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
            "Epoch 98/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
            "Epoch 99/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
            "Epoch 100/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
            "Epoch 101/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
            "Epoch 102/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
            "Epoch 103/1000\n",
            "700/700 [==============================] - 0s 527us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
            "Epoch 104/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
            "Epoch 105/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
            "Epoch 106/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
            "Epoch 107/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
            "Epoch 108/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
            "Epoch 109/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
            "Epoch 110/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
            "Epoch 111/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
            "Epoch 112/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
            "Epoch 113/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
            "Epoch 114/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
            "Epoch 115/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
            "Epoch 116/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
            "Epoch 117/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
            "Epoch 118/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
            "Epoch 119/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n",
            "Epoch 120/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
            "Epoch 121/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
            "Epoch 122/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
            "Epoch 123/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
            "Epoch 124/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
            "Epoch 125/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
            "Epoch 126/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
            "Epoch 127/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
            "Epoch 128/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
            "Epoch 129/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
            "Epoch 130/1000\n",
            "700/700 [==============================] - 0s 447us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
            "Epoch 131/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
            "Epoch 132/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
            "Epoch 133/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
            "Epoch 134/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
            "Epoch 135/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
            "Epoch 136/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
            "Epoch 137/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
            "Epoch 138/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
            "Epoch 139/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
            "Epoch 140/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
            "Epoch 141/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
            "Epoch 142/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
            "Epoch 143/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
            "Epoch 144/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
            "Epoch 145/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
            "Epoch 146/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
            "Epoch 147/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
            "Epoch 148/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
            "Epoch 149/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
            "Epoch 150/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
            "Epoch 151/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
            "Epoch 152/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
            "Epoch 153/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
            "Epoch 154/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
            "Epoch 155/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
            "Epoch 156/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
            "Epoch 157/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
            "Epoch 158/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
            "Epoch 159/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
            "Epoch 160/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
            "Epoch 161/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
            "Epoch 162/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
            "Epoch 163/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
            "Epoch 164/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
            "Epoch 165/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
            "Epoch 166/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
            "Epoch 167/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
            "Epoch 168/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
            "Epoch 169/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
            "Epoch 170/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
            "Epoch 171/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
            "Epoch 172/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
            "Epoch 173/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
            "Epoch 174/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
            "Epoch 175/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
            "Epoch 176/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
            "Epoch 177/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
            "Epoch 178/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
            "Epoch 179/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
            "Epoch 180/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
            "Epoch 181/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
            "Epoch 182/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
            "Epoch 183/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
            "Epoch 184/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
            "Epoch 185/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
            "Epoch 186/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
            "Epoch 187/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
            "Epoch 188/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
            "Epoch 189/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
            "Epoch 190/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
            "Epoch 191/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
            "Epoch 192/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
            "Epoch 193/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
            "Epoch 194/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
            "Epoch 195/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
            "Epoch 196/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
            "Epoch 197/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
            "Epoch 198/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
            "Epoch 199/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
            "Epoch 200/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
            "Epoch 201/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
            "Epoch 202/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
            "Epoch 203/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
            "Epoch 204/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
            "Epoch 205/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
            "Epoch 206/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
            "Epoch 207/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
            "Epoch 208/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
            "Epoch 209/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
            "Epoch 210/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
            "Epoch 211/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
            "Epoch 212/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
            "Epoch 213/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
            "Epoch 214/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
            "Epoch 215/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
            "Epoch 216/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
            "Epoch 217/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
            "Epoch 218/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
            "Epoch 219/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
            "Epoch 220/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
            "Epoch 221/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
            "Epoch 222/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
            "Epoch 223/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
            "Epoch 224/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
            "Epoch 225/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
            "Epoch 226/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
            "Epoch 227/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
            "Epoch 228/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
            "Epoch 229/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
            "Epoch 230/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
            "Epoch 231/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8605 - val_acc: 0.2200\n",
            "Epoch 232/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8730 - val_acc: 0.2133\n",
            "Epoch 233/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
            "Epoch 234/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
            "Epoch 235/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
            "Epoch 236/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
            "Epoch 237/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
            "Epoch 238/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
            "Epoch 239/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
            "Epoch 240/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
            "Epoch 241/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
            "Epoch 242/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
            "Epoch 243/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
            "Epoch 244/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
            "Epoch 245/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8838 - val_acc: 0.2233\n",
            "Epoch 246/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
            "Epoch 247/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
            "Epoch 248/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
            "Epoch 249/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
            "Epoch 250/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
            "Epoch 251/1000\n",
            "700/700 [==============================] - 0s 389us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
            "Epoch 252/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
            "Epoch 253/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
            "Epoch 254/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
            "Epoch 255/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
            "Epoch 256/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
            "Epoch 257/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
            "Epoch 258/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
            "Epoch 259/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
            "Epoch 260/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
            "Epoch 261/1000\n",
            "700/700 [==============================] - 0s 391us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
            "Epoch 262/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
            "Epoch 263/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
            "Epoch 264/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
            "Epoch 265/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
            "Epoch 266/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
            "Epoch 267/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8918 - val_acc: 0.2300\n",
            "Epoch 268/1000\n",
            "700/700 [==============================] - 0s 392us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
            "Epoch 269/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
            "Epoch 270/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
            "Epoch 271/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
            "Epoch 272/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
            "Epoch 273/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
            "Epoch 274/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
            "Epoch 275/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
            "Epoch 276/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
            "Epoch 277/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
            "Epoch 278/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
            "Epoch 279/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
            "Epoch 280/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
            "Epoch 281/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
            "Epoch 282/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
            "Epoch 283/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
            "Epoch 284/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
            "Epoch 285/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
            "Epoch 286/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
            "Epoch 287/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
            "Epoch 288/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
            "Epoch 289/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
            "Epoch 290/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
            "Epoch 291/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
            "Epoch 292/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
            "Epoch 293/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
            "Epoch 294/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
            "Epoch 295/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
            "Epoch 296/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
            "Epoch 297/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
            "Epoch 298/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
            "Epoch 299/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
            "Epoch 300/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
            "Epoch 301/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.5469 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
            "Epoch 302/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
            "Epoch 303/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5464 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
            "Epoch 304/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
            "Epoch 305/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.5432 - acc: 0.3643 - val_loss: 1.9140 - val_acc: 0.2267\n",
            "Epoch 306/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5458 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2233\n",
            "Epoch 307/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.5436 - acc: 0.3671 - val_loss: 1.9064 - val_acc: 0.2267\n",
            "Epoch 308/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9129 - val_acc: 0.2333\n",
            "Epoch 309/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5435 - acc: 0.3643 - val_loss: 1.9120 - val_acc: 0.2367\n",
            "Epoch 310/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.5448 - acc: 0.3671 - val_loss: 1.9110 - val_acc: 0.2167\n",
            "Epoch 311/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5426 - acc: 0.3586 - val_loss: 1.9058 - val_acc: 0.2300\n",
            "Epoch 312/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9273 - val_acc: 0.2367\n",
            "Epoch 313/1000\n",
            "700/700 [==============================] - 0s 396us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9056 - val_acc: 0.2633\n",
            "Epoch 314/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5433 - acc: 0.3686 - val_loss: 1.9131 - val_acc: 0.2300\n",
            "Epoch 315/1000\n",
            "700/700 [==============================] - 0s 498us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9118 - val_acc: 0.2233\n",
            "Epoch 316/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5404 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2233\n",
            "Epoch 317/1000\n",
            "700/700 [==============================] - 0s 507us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9213 - val_acc: 0.2333\n",
            "Epoch 318/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9096 - val_acc: 0.2300\n",
            "Epoch 319/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9092 - val_acc: 0.2300\n",
            "Epoch 320/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9278 - val_acc: 0.2233\n",
            "Epoch 321/1000\n",
            "700/700 [==============================] - 0s 506us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9258 - val_acc: 0.2300\n",
            "Epoch 322/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9181 - val_acc: 0.2533\n",
            "Epoch 323/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9197 - val_acc: 0.2300\n",
            "Epoch 324/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5373 - acc: 0.3657 - val_loss: 1.9227 - val_acc: 0.2200\n",
            "Epoch 325/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.5387 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2133\n",
            "Epoch 326/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5365 - acc: 0.3614 - val_loss: 1.9227 - val_acc: 0.2200\n",
            "Epoch 327/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5359 - acc: 0.3743 - val_loss: 1.9378 - val_acc: 0.2333\n",
            "Epoch 328/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9307 - val_acc: 0.2233\n",
            "Epoch 329/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5354 - acc: 0.3714 - val_loss: 1.9147 - val_acc: 0.2300\n",
            "Epoch 330/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.5351 - acc: 0.3600 - val_loss: 1.9222 - val_acc: 0.2333\n",
            "Epoch 331/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5338 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2200\n",
            "Epoch 332/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5346 - acc: 0.3571 - val_loss: 1.9340 - val_acc: 0.2500\n",
            "Epoch 333/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5358 - acc: 0.3671 - val_loss: 1.9234 - val_acc: 0.2233\n",
            "Epoch 334/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9289 - val_acc: 0.2233\n",
            "Epoch 335/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5327 - acc: 0.3757 - val_loss: 1.9246 - val_acc: 0.2567\n",
            "Epoch 336/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5335 - acc: 0.3786 - val_loss: 1.9184 - val_acc: 0.2300\n",
            "Epoch 337/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.5330 - acc: 0.3757 - val_loss: 1.9324 - val_acc: 0.2300\n",
            "Epoch 338/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9238 - val_acc: 0.2133\n",
            "Epoch 339/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9157 - val_acc: 0.2167\n",
            "Epoch 340/1000\n",
            "700/700 [==============================] - 0s 475us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9403 - val_acc: 0.2267\n",
            "Epoch 341/1000\n",
            "700/700 [==============================] - 0s 550us/step - loss: 1.5317 - acc: 0.3757 - val_loss: 1.9258 - val_acc: 0.2267\n",
            "Epoch 342/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9441 - val_acc: 0.2167\n",
            "Epoch 343/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5310 - acc: 0.3686 - val_loss: 1.9333 - val_acc: 0.2267\n",
            "Epoch 344/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9431 - val_acc: 0.2300\n",
            "Epoch 345/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9443 - val_acc: 0.2567\n",
            "Epoch 346/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9314 - val_acc: 0.2267\n",
            "Epoch 347/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5277 - acc: 0.3800 - val_loss: 1.9199 - val_acc: 0.2200\n",
            "Epoch 348/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2167\n",
            "Epoch 349/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9273 - val_acc: 0.2133\n",
            "Epoch 350/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
            "Epoch 351/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9309 - val_acc: 0.2333\n",
            "Epoch 352/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
            "Epoch 353/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2300\n",
            "Epoch 354/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5279 - acc: 0.3700 - val_loss: 1.9350 - val_acc: 0.2167\n",
            "Epoch 355/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9553 - val_acc: 0.2267\n",
            "Epoch 356/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9442 - val_acc: 0.2433\n",
            "Epoch 357/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.5259 - acc: 0.3743 - val_loss: 1.9355 - val_acc: 0.2267\n",
            "Epoch 358/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9494 - val_acc: 0.2233\n",
            "Epoch 359/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9450 - val_acc: 0.2133\n",
            "Epoch 360/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9454 - val_acc: 0.2233\n",
            "Epoch 361/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9485 - val_acc: 0.2300\n",
            "Epoch 362/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5240 - acc: 0.3643 - val_loss: 1.9508 - val_acc: 0.2267\n",
            "Epoch 363/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5215 - acc: 0.3757 - val_loss: 1.9527 - val_acc: 0.2333\n",
            "Epoch 364/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9381 - val_acc: 0.2300\n",
            "Epoch 365/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9524 - val_acc: 0.2267\n",
            "Epoch 366/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5222 - acc: 0.3686 - val_loss: 1.9406 - val_acc: 0.2133\n",
            "Epoch 367/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5221 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2300\n",
            "Epoch 368/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9551 - val_acc: 0.2367\n",
            "Epoch 369/1000\n",
            "700/700 [==============================] - 0s 396us/step - loss: 1.5207 - acc: 0.3629 - val_loss: 1.9321 - val_acc: 0.2367\n",
            "Epoch 370/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9534 - val_acc: 0.2400\n",
            "Epoch 371/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9508 - val_acc: 0.2233\n",
            "Epoch 372/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9590 - val_acc: 0.2333\n",
            "Epoch 373/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
            "Epoch 374/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9514 - val_acc: 0.2267\n",
            "Epoch 375/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9386 - val_acc: 0.2267\n",
            "Epoch 376/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5182 - acc: 0.3800 - val_loss: 1.9487 - val_acc: 0.2167\n",
            "Epoch 377/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9760 - val_acc: 0.2267\n",
            "Epoch 378/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2367\n",
            "Epoch 379/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9516 - val_acc: 0.2367\n",
            "Epoch 380/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9602 - val_acc: 0.2567\n",
            "Epoch 381/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9711 - val_acc: 0.2167\n",
            "Epoch 382/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9585 - val_acc: 0.2267\n",
            "Epoch 383/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9714 - val_acc: 0.2433\n",
            "Epoch 384/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9509 - val_acc: 0.2233\n",
            "Epoch 385/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9579 - val_acc: 0.2267\n",
            "Epoch 386/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9502 - val_acc: 0.2333\n",
            "Epoch 387/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9578 - val_acc: 0.2300\n",
            "Epoch 388/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9668 - val_acc: 0.2467\n",
            "Epoch 389/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5158 - acc: 0.3800 - val_loss: 1.9490 - val_acc: 0.2267\n",
            "Epoch 390/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9572 - val_acc: 0.2400\n",
            "Epoch 391/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9539 - val_acc: 0.2367\n",
            "Epoch 392/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9599 - val_acc: 0.2233\n",
            "Epoch 393/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.5137 - acc: 0.3757 - val_loss: 1.9730 - val_acc: 0.2233\n",
            "Epoch 394/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9565 - val_acc: 0.2267\n",
            "Epoch 395/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5132 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2167\n",
            "Epoch 396/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5124 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
            "Epoch 397/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5111 - acc: 0.3857 - val_loss: 1.9755 - val_acc: 0.2367\n",
            "Epoch 398/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9588 - val_acc: 0.2200\n",
            "Epoch 399/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9872 - val_acc: 0.2333\n",
            "Epoch 400/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9599 - val_acc: 0.2167\n",
            "Epoch 401/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
            "Epoch 402/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9650 - val_acc: 0.2233\n",
            "Epoch 403/1000\n",
            "700/700 [==============================] - 0s 393us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2200\n",
            "Epoch 404/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9678 - val_acc: 0.2333\n",
            "Epoch 405/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9811 - val_acc: 0.2300\n",
            "Epoch 406/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9745 - val_acc: 0.2200\n",
            "Epoch 407/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9792 - val_acc: 0.2267\n",
            "Epoch 408/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9706 - val_acc: 0.2267\n",
            "Epoch 409/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9783 - val_acc: 0.2367\n",
            "Epoch 410/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9611 - val_acc: 0.2267\n",
            "Epoch 411/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
            "Epoch 412/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9719 - val_acc: 0.2233\n",
            "Epoch 413/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9760 - val_acc: 0.2333\n",
            "Epoch 414/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5043 - acc: 0.3786 - val_loss: 1.9842 - val_acc: 0.2333\n",
            "Epoch 415/1000\n",
            "700/700 [==============================] - 0s 486us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9778 - val_acc: 0.2333\n",
            "Epoch 416/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9889 - val_acc: 0.2267\n",
            "Epoch 417/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9804 - val_acc: 0.2200\n",
            "Epoch 418/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2333\n",
            "Epoch 419/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9663 - val_acc: 0.2200\n",
            "Epoch 420/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
            "Epoch 421/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.5011 - acc: 0.3829 - val_loss: 1.9692 - val_acc: 0.2433\n",
            "Epoch 422/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.5004 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
            "Epoch 423/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2333\n",
            "Epoch 424/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9678 - val_acc: 0.2200\n",
            "Epoch 425/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9619 - val_acc: 0.2400\n",
            "Epoch 426/1000\n",
            "700/700 [==============================] - 0s 484us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
            "Epoch 427/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9833 - val_acc: 0.2533\n",
            "Epoch 428/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
            "Epoch 429/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9696 - val_acc: 0.2300\n",
            "Epoch 430/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4977 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2467\n",
            "Epoch 431/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4990 - acc: 0.3786 - val_loss: 1.9880 - val_acc: 0.2333\n",
            "Epoch 432/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2233\n",
            "Epoch 433/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4967 - acc: 0.3814 - val_loss: 1.9850 - val_acc: 0.2367\n",
            "Epoch 434/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.4976 - acc: 0.3743 - val_loss: 1.9881 - val_acc: 0.2233\n",
            "Epoch 435/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4957 - acc: 0.3900 - val_loss: 1.9819 - val_acc: 0.2267\n",
            "Epoch 436/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9691 - val_acc: 0.2233\n",
            "Epoch 437/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4957 - acc: 0.3943 - val_loss: 1.9951 - val_acc: 0.2200\n",
            "Epoch 438/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9635 - val_acc: 0.2300\n",
            "Epoch 439/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.4946 - acc: 0.3771 - val_loss: 1.9781 - val_acc: 0.2233\n",
            "Epoch 440/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4960 - acc: 0.3800 - val_loss: 1.9796 - val_acc: 0.2300\n",
            "Epoch 441/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9825 - val_acc: 0.2300\n",
            "Epoch 442/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4944 - acc: 0.3829 - val_loss: 1.9939 - val_acc: 0.2233\n",
            "Epoch 443/1000\n",
            "700/700 [==============================] - 0s 491us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9899 - val_acc: 0.2400\n",
            "Epoch 444/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4946 - acc: 0.3829 - val_loss: 1.9926 - val_acc: 0.2233\n",
            "Epoch 445/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 1.9955 - val_acc: 0.2300\n",
            "Epoch 446/1000\n",
            "700/700 [==============================] - 0s 488us/step - loss: 1.4931 - acc: 0.3886 - val_loss: 2.0029 - val_acc: 0.2267\n",
            "Epoch 447/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4926 - acc: 0.3800 - val_loss: 2.0142 - val_acc: 0.2300\n",
            "Epoch 448/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9924 - val_acc: 0.2267\n",
            "Epoch 449/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0006 - val_acc: 0.2333\n",
            "Epoch 450/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2233\n",
            "Epoch 451/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9986 - val_acc: 0.2233\n",
            "Epoch 452/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
            "Epoch 453/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2333\n",
            "Epoch 454/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9967 - val_acc: 0.2333\n",
            "Epoch 455/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9881 - val_acc: 0.2233\n",
            "Epoch 456/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
            "Epoch 457/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9972 - val_acc: 0.2333\n",
            "Epoch 458/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9926 - val_acc: 0.2267\n",
            "Epoch 459/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9909 - val_acc: 0.2433\n",
            "Epoch 460/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0007 - val_acc: 0.2300\n",
            "Epoch 461/1000\n",
            "700/700 [==============================] - 0s 396us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0033 - val_acc: 0.2300\n",
            "Epoch 462/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9937 - val_acc: 0.2267\n",
            "Epoch 463/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4872 - acc: 0.3857 - val_loss: 2.0002 - val_acc: 0.2467\n",
            "Epoch 464/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 1.9888 - val_acc: 0.2333\n",
            "Epoch 465/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9972 - val_acc: 0.2233\n",
            "Epoch 466/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0004 - val_acc: 0.2267\n",
            "Epoch 467/1000\n",
            "700/700 [==============================] - 0s 528us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2300\n",
            "Epoch 468/1000\n",
            "700/700 [==============================] - 0s 506us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9905 - val_acc: 0.2267\n",
            "Epoch 469/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0313 - val_acc: 0.2333\n",
            "Epoch 470/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 2.0096 - val_acc: 0.2233\n",
            "Epoch 471/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.4859 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2267\n",
            "Epoch 472/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4845 - acc: 0.3971 - val_loss: 2.0080 - val_acc: 0.2367\n",
            "Epoch 473/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4850 - acc: 0.3914 - val_loss: 2.0121 - val_acc: 0.2367\n",
            "Epoch 474/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9976 - val_acc: 0.2267\n",
            "Epoch 475/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0047 - val_acc: 0.2233\n",
            "Epoch 476/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4835 - acc: 0.3900 - val_loss: 2.0056 - val_acc: 0.2267\n",
            "Epoch 477/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0095 - val_acc: 0.2267\n",
            "Epoch 478/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0056 - val_acc: 0.2333\n",
            "Epoch 479/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4833 - acc: 0.3900 - val_loss: 2.0015 - val_acc: 0.2300\n",
            "Epoch 480/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4824 - acc: 0.3957 - val_loss: 2.0102 - val_acc: 0.2367\n",
            "Epoch 481/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
            "Epoch 482/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0164 - val_acc: 0.2300\n",
            "Epoch 483/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0144 - val_acc: 0.2367\n",
            "Epoch 484/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0162 - val_acc: 0.2400\n",
            "Epoch 485/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4811 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2300\n",
            "Epoch 486/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0074 - val_acc: 0.2467\n",
            "Epoch 487/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0075 - val_acc: 0.2500\n",
            "Epoch 488/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0157 - val_acc: 0.2500\n",
            "Epoch 489/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2267\n",
            "Epoch 490/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0000 - val_acc: 0.2333\n",
            "Epoch 491/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4808 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
            "Epoch 492/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0007 - val_acc: 0.2267\n",
            "Epoch 493/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0076 - val_acc: 0.2333\n",
            "Epoch 494/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4802 - acc: 0.3900 - val_loss: 2.0072 - val_acc: 0.2233\n",
            "Epoch 495/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4792 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2333\n",
            "Epoch 496/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0112 - val_acc: 0.2433\n",
            "Epoch 497/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0122 - val_acc: 0.2467\n",
            "Epoch 498/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0468 - val_acc: 0.2367\n",
            "Epoch 499/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4775 - acc: 0.4014 - val_loss: 2.0281 - val_acc: 0.2367\n",
            "Epoch 500/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0262 - val_acc: 0.2367\n",
            "Epoch 501/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0258 - val_acc: 0.2300\n",
            "Epoch 502/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4760 - acc: 0.3943 - val_loss: 2.0261 - val_acc: 0.2267\n",
            "Epoch 503/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0202 - val_acc: 0.2267\n",
            "Epoch 504/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0240 - val_acc: 0.2267\n",
            "Epoch 505/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0196 - val_acc: 0.2400\n",
            "Epoch 506/1000\n",
            "700/700 [==============================] - 0s 396us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0154 - val_acc: 0.2300\n",
            "Epoch 507/1000\n",
            "700/700 [==============================] - 0s 396us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
            "Epoch 508/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0240 - val_acc: 0.2267\n",
            "Epoch 509/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0373 - val_acc: 0.2333\n",
            "Epoch 510/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
            "Epoch 511/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4737 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2267\n",
            "Epoch 512/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4739 - acc: 0.3971 - val_loss: 2.0106 - val_acc: 0.2467\n",
            "Epoch 513/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4732 - acc: 0.3986 - val_loss: 2.0137 - val_acc: 0.2433\n",
            "Epoch 514/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0268 - val_acc: 0.2267\n",
            "Epoch 515/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.4734 - acc: 0.4014 - val_loss: 2.0250 - val_acc: 0.2300\n",
            "Epoch 516/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2267\n",
            "Epoch 517/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0338 - val_acc: 0.2500\n",
            "Epoch 518/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4740 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2267\n",
            "Epoch 519/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0238 - val_acc: 0.2300\n",
            "Epoch 520/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0307 - val_acc: 0.2400\n",
            "Epoch 521/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.4713 - acc: 0.4129 - val_loss: 2.0126 - val_acc: 0.2333\n",
            "Epoch 522/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2267\n",
            "Epoch 523/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0293 - val_acc: 0.2267\n",
            "Epoch 524/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0230 - val_acc: 0.2333\n",
            "Epoch 525/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0285 - val_acc: 0.2467\n",
            "Epoch 526/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.4711 - acc: 0.4029 - val_loss: 2.0247 - val_acc: 0.2267\n",
            "Epoch 527/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0259 - val_acc: 0.2300\n",
            "Epoch 528/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0291 - val_acc: 0.2267\n",
            "Epoch 529/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0337 - val_acc: 0.2267\n",
            "Epoch 530/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4686 - acc: 0.4000 - val_loss: 2.0412 - val_acc: 0.2267\n",
            "Epoch 531/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
            "Epoch 532/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
            "Epoch 533/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0311 - val_acc: 0.2300\n",
            "Epoch 534/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
            "Epoch 535/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0499 - val_acc: 0.2433\n",
            "Epoch 536/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0468 - val_acc: 0.2267\n",
            "Epoch 537/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0293 - val_acc: 0.2300\n",
            "Epoch 538/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4672 - acc: 0.3957 - val_loss: 2.0361 - val_acc: 0.2367\n",
            "Epoch 539/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0313 - val_acc: 0.2267\n",
            "Epoch 540/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2267\n",
            "Epoch 541/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0371 - val_acc: 0.2267\n",
            "Epoch 542/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4665 - acc: 0.4057 - val_loss: 2.0430 - val_acc: 0.2433\n",
            "Epoch 543/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0292 - val_acc: 0.2333\n",
            "Epoch 544/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0243 - val_acc: 0.2367\n",
            "Epoch 545/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0327 - val_acc: 0.2300\n",
            "Epoch 546/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4635 - acc: 0.4000 - val_loss: 2.0464 - val_acc: 0.2533\n",
            "Epoch 547/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4657 - acc: 0.4000 - val_loss: 2.0517 - val_acc: 0.2400\n",
            "Epoch 548/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0295 - val_acc: 0.2300\n",
            "Epoch 549/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0262 - val_acc: 0.2333\n",
            "Epoch 550/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
            "Epoch 551/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.4647 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2300\n",
            "Epoch 552/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0365 - val_acc: 0.2333\n",
            "Epoch 553/1000\n",
            "700/700 [==============================] - 0s 509us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
            "Epoch 554/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4630 - acc: 0.3986 - val_loss: 2.0435 - val_acc: 0.2300\n",
            "Epoch 555/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0446 - val_acc: 0.2400\n",
            "Epoch 556/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0385 - val_acc: 0.2467\n",
            "Epoch 557/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2500\n",
            "Epoch 558/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4631 - acc: 0.4029 - val_loss: 2.0380 - val_acc: 0.2333\n",
            "Epoch 559/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0413 - val_acc: 0.2533\n",
            "Epoch 560/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0446 - val_acc: 0.2567\n",
            "Epoch 561/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0394 - val_acc: 0.2267\n",
            "Epoch 562/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4619 - acc: 0.4029 - val_loss: 2.0325 - val_acc: 0.2300\n",
            "Epoch 563/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
            "Epoch 564/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
            "Epoch 565/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0375 - val_acc: 0.2333\n",
            "Epoch 566/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0473 - val_acc: 0.2300\n",
            "Epoch 567/1000\n",
            "700/700 [==============================] - 0s 491us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0504 - val_acc: 0.2300\n",
            "Epoch 568/1000\n",
            "700/700 [==============================] - 0s 442us/step - loss: 1.4598 - acc: 0.4057 - val_loss: 2.0486 - val_acc: 0.2433\n",
            "Epoch 569/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4594 - acc: 0.4057 - val_loss: 2.0432 - val_acc: 0.2533\n",
            "Epoch 570/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4586 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
            "Epoch 571/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2300\n",
            "Epoch 572/1000\n",
            "700/700 [==============================] - 0s 574us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2333\n",
            "Epoch 573/1000\n",
            "700/700 [==============================] - 0s 517us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0551 - val_acc: 0.2533\n",
            "Epoch 574/1000\n",
            "700/700 [==============================] - 0s 482us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0408 - val_acc: 0.2500\n",
            "Epoch 575/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0449 - val_acc: 0.2267\n",
            "Epoch 576/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0468 - val_acc: 0.2300\n",
            "Epoch 577/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4583 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2300\n",
            "Epoch 578/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4577 - acc: 0.4071 - val_loss: 2.0453 - val_acc: 0.2367\n",
            "Epoch 579/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4584 - acc: 0.4057 - val_loss: 2.0428 - val_acc: 0.2267\n",
            "Epoch 580/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4574 - acc: 0.4086 - val_loss: 2.0531 - val_acc: 0.2367\n",
            "Epoch 581/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4570 - acc: 0.4071 - val_loss: 2.0488 - val_acc: 0.2567\n",
            "Epoch 582/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0513 - val_acc: 0.2267\n",
            "Epoch 583/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0529 - val_acc: 0.2267\n",
            "Epoch 584/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2267\n",
            "Epoch 585/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0556 - val_acc: 0.2300\n",
            "Epoch 586/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.4549 - acc: 0.4043 - val_loss: 2.0555 - val_acc: 0.2500\n",
            "Epoch 587/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2333\n",
            "Epoch 588/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4560 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2300\n",
            "Epoch 589/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4553 - acc: 0.4057 - val_loss: 2.0576 - val_acc: 0.2267\n",
            "Epoch 590/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
            "Epoch 591/1000\n",
            "700/700 [==============================] - 0s 524us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0605 - val_acc: 0.2267\n",
            "Epoch 592/1000\n",
            "700/700 [==============================] - 0s 554us/step - loss: 1.4544 - acc: 0.4086 - val_loss: 2.0557 - val_acc: 0.2333\n",
            "Epoch 593/1000\n",
            "700/700 [==============================] - 0s 527us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0498 - val_acc: 0.2267\n",
            "Epoch 594/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4540 - acc: 0.4129 - val_loss: 2.0513 - val_acc: 0.2333\n",
            "Epoch 595/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4543 - acc: 0.4057 - val_loss: 2.0569 - val_acc: 0.2433\n",
            "Epoch 596/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0472 - val_acc: 0.2300\n",
            "Epoch 597/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0491 - val_acc: 0.2500\n",
            "Epoch 598/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4537 - acc: 0.3986 - val_loss: 2.0563 - val_acc: 0.2267\n",
            "Epoch 599/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0478 - val_acc: 0.2333\n",
            "Epoch 600/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0625 - val_acc: 0.2300\n",
            "Epoch 601/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0623 - val_acc: 0.2433\n",
            "Epoch 602/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4526 - acc: 0.4029 - val_loss: 2.0585 - val_acc: 0.2333\n",
            "Epoch 603/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0504 - val_acc: 0.2400\n",
            "Epoch 604/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4525 - acc: 0.4029 - val_loss: 2.0489 - val_acc: 0.2433\n",
            "Epoch 605/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0553 - val_acc: 0.2367\n",
            "Epoch 606/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
            "Epoch 607/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4518 - acc: 0.4100 - val_loss: 2.0580 - val_acc: 0.2300\n",
            "Epoch 608/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2367\n",
            "Epoch 609/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4500 - acc: 0.4157 - val_loss: 2.0635 - val_acc: 0.2567\n",
            "Epoch 610/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
            "Epoch 611/1000\n",
            "700/700 [==============================] - 0s 514us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0608 - val_acc: 0.2367\n",
            "Epoch 612/1000\n",
            "700/700 [==============================] - 0s 543us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
            "Epoch 613/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4505 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2300\n",
            "Epoch 614/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0686 - val_acc: 0.2500\n",
            "Epoch 615/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4502 - acc: 0.4129 - val_loss: 2.0535 - val_acc: 0.2533\n",
            "Epoch 616/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4495 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2333\n",
            "Epoch 617/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0653 - val_acc: 0.2533\n",
            "Epoch 618/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0597 - val_acc: 0.2400\n",
            "Epoch 619/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0671 - val_acc: 0.2333\n",
            "Epoch 620/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4488 - acc: 0.4171 - val_loss: 2.0564 - val_acc: 0.2300\n",
            "Epoch 621/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4487 - acc: 0.4129 - val_loss: 2.0741 - val_acc: 0.2333\n",
            "Epoch 622/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0741 - val_acc: 0.2367\n",
            "Epoch 623/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0690 - val_acc: 0.2267\n",
            "Epoch 624/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0689 - val_acc: 0.2367\n",
            "Epoch 625/1000\n",
            "700/700 [==============================] - 0s 395us/step - loss: 1.4479 - acc: 0.4029 - val_loss: 2.0724 - val_acc: 0.2367\n",
            "Epoch 626/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0535 - val_acc: 0.2367\n",
            "Epoch 627/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0632 - val_acc: 0.2333\n",
            "Epoch 628/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4459 - acc: 0.4157 - val_loss: 2.0503 - val_acc: 0.2400\n",
            "Epoch 629/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0615 - val_acc: 0.2333\n",
            "Epoch 630/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4460 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2333\n",
            "Epoch 631/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0818 - val_acc: 0.2400\n",
            "Epoch 632/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2400\n",
            "Epoch 633/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0829 - val_acc: 0.2367\n",
            "Epoch 634/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0715 - val_acc: 0.2333\n",
            "Epoch 635/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0653 - val_acc: 0.2567\n",
            "Epoch 636/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4463 - acc: 0.4129 - val_loss: 2.0669 - val_acc: 0.2333\n",
            "Epoch 637/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0764 - val_acc: 0.2367\n",
            "Epoch 638/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0816 - val_acc: 0.2300\n",
            "Epoch 639/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
            "Epoch 640/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4441 - acc: 0.4157 - val_loss: 2.0581 - val_acc: 0.2367\n",
            "Epoch 641/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4437 - acc: 0.4143 - val_loss: 2.0742 - val_acc: 0.2467\n",
            "Epoch 642/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4448 - acc: 0.4100 - val_loss: 2.0819 - val_acc: 0.2433\n",
            "Epoch 643/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0856 - val_acc: 0.2300\n",
            "Epoch 644/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4440 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2367\n",
            "Epoch 645/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0797 - val_acc: 0.2333\n",
            "Epoch 646/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
            "Epoch 647/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4423 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2367\n",
            "Epoch 648/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0860 - val_acc: 0.2333\n",
            "Epoch 649/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0823 - val_acc: 0.2333\n",
            "Epoch 650/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0725 - val_acc: 0.2333\n",
            "Epoch 651/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4418 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
            "Epoch 652/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4430 - acc: 0.4114 - val_loss: 2.0737 - val_acc: 0.2333\n",
            "Epoch 653/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4415 - acc: 0.4171 - val_loss: 2.0781 - val_acc: 0.2433\n",
            "Epoch 654/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4414 - acc: 0.4143 - val_loss: 2.0641 - val_acc: 0.2467\n",
            "Epoch 655/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4406 - acc: 0.4100 - val_loss: 2.0746 - val_acc: 0.2533\n",
            "Epoch 656/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0850 - val_acc: 0.2433\n",
            "Epoch 657/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0809 - val_acc: 0.2300\n",
            "Epoch 658/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4409 - acc: 0.4143 - val_loss: 2.0781 - val_acc: 0.2367\n",
            "Epoch 659/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4404 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2467\n",
            "Epoch 660/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0796 - val_acc: 0.2367\n",
            "Epoch 661/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4418 - acc: 0.4086 - val_loss: 2.0753 - val_acc: 0.2367\n",
            "Epoch 662/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0794 - val_acc: 0.2367\n",
            "Epoch 663/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0953 - val_acc: 0.2400\n",
            "Epoch 664/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4394 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
            "Epoch 665/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.0887 - val_acc: 0.2333\n",
            "Epoch 666/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0808 - val_acc: 0.2533\n",
            "Epoch 667/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0751 - val_acc: 0.2367\n",
            "Epoch 668/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0902 - val_acc: 0.2567\n",
            "Epoch 669/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4382 - acc: 0.4157 - val_loss: 2.0931 - val_acc: 0.2333\n",
            "Epoch 670/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.0815 - val_acc: 0.2333\n",
            "Epoch 671/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0801 - val_acc: 0.2533\n",
            "Epoch 672/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4382 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2367\n",
            "Epoch 673/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4384 - acc: 0.4186 - val_loss: 2.0821 - val_acc: 0.2400\n",
            "Epoch 674/1000\n",
            "700/700 [==============================] - 0s 399us/step - loss: 1.4374 - acc: 0.4086 - val_loss: 2.1027 - val_acc: 0.2433\n",
            "Epoch 675/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
            "Epoch 676/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2567\n",
            "Epoch 677/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0972 - val_acc: 0.2300\n",
            "Epoch 678/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4355 - acc: 0.4200 - val_loss: 2.0724 - val_acc: 0.2333\n",
            "Epoch 679/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0890 - val_acc: 0.2367\n",
            "Epoch 680/1000\n",
            "700/700 [==============================] - 0s 396us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
            "Epoch 681/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0805 - val_acc: 0.2400\n",
            "Epoch 682/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0854 - val_acc: 0.2567\n",
            "Epoch 683/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0779 - val_acc: 0.2500\n",
            "Epoch 684/1000\n",
            "700/700 [==============================] - 0s 540us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0887 - val_acc: 0.2600\n",
            "Epoch 685/1000\n",
            "700/700 [==============================] - 0s 495us/step - loss: 1.4356 - acc: 0.4143 - val_loss: 2.0846 - val_acc: 0.2567\n",
            "Epoch 686/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4352 - acc: 0.4200 - val_loss: 2.1067 - val_acc: 0.2533\n",
            "Epoch 687/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0772 - val_acc: 0.2367\n",
            "Epoch 688/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0829 - val_acc: 0.2400\n",
            "Epoch 689/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0925 - val_acc: 0.2367\n",
            "Epoch 690/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.0995 - val_acc: 0.2333\n",
            "Epoch 691/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4337 - acc: 0.4229 - val_loss: 2.0944 - val_acc: 0.2333\n",
            "Epoch 692/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
            "Epoch 693/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
            "Epoch 694/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4335 - acc: 0.4186 - val_loss: 2.1067 - val_acc: 0.2467\n",
            "Epoch 695/1000\n",
            "700/700 [==============================] - 0s 509us/step - loss: 1.4348 - acc: 0.4171 - val_loss: 2.0871 - val_acc: 0.2567\n",
            "Epoch 696/1000\n",
            "700/700 [==============================] - 0s 504us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0991 - val_acc: 0.2333\n",
            "Epoch 697/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4337 - acc: 0.4186 - val_loss: 2.1061 - val_acc: 0.2467\n",
            "Epoch 698/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.4333 - acc: 0.4257 - val_loss: 2.0948 - val_acc: 0.2433\n",
            "Epoch 699/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.0957 - val_acc: 0.2400\n",
            "Epoch 700/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0952 - val_acc: 0.2467\n",
            "Epoch 701/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4316 - acc: 0.4171 - val_loss: 2.0921 - val_acc: 0.2433\n",
            "Epoch 702/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0981 - val_acc: 0.2367\n",
            "Epoch 703/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1061 - val_acc: 0.2333\n",
            "Epoch 704/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4325 - acc: 0.4214 - val_loss: 2.0935 - val_acc: 0.2433\n",
            "Epoch 705/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0879 - val_acc: 0.2400\n",
            "Epoch 706/1000\n",
            "700/700 [==============================] - 0s 506us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0806 - val_acc: 0.2400\n",
            "Epoch 707/1000\n",
            "700/700 [==============================] - 0s 521us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.0931 - val_acc: 0.2367\n",
            "Epoch 708/1000\n",
            "700/700 [==============================] - 0s 516us/step - loss: 1.4316 - acc: 0.4214 - val_loss: 2.0923 - val_acc: 0.2333\n",
            "Epoch 709/1000\n",
            "700/700 [==============================] - 0s 565us/step - loss: 1.4296 - acc: 0.4186 - val_loss: 2.1160 - val_acc: 0.2533\n",
            "Epoch 710/1000\n",
            "700/700 [==============================] - 0s 564us/step - loss: 1.4314 - acc: 0.4229 - val_loss: 2.0957 - val_acc: 0.2467\n",
            "Epoch 711/1000\n",
            "700/700 [==============================] - 0s 504us/step - loss: 1.4304 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2367\n",
            "Epoch 712/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.4300 - acc: 0.4214 - val_loss: 2.1035 - val_acc: 0.2567\n",
            "Epoch 713/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4310 - acc: 0.4186 - val_loss: 2.0861 - val_acc: 0.2400\n",
            "Epoch 714/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4305 - acc: 0.4243 - val_loss: 2.0996 - val_acc: 0.2367\n",
            "Epoch 715/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.0936 - val_acc: 0.2600\n",
            "Epoch 716/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4305 - acc: 0.4157 - val_loss: 2.1060 - val_acc: 0.2367\n",
            "Epoch 717/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1014 - val_acc: 0.2367\n",
            "Epoch 718/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4289 - acc: 0.4186 - val_loss: 2.1246 - val_acc: 0.2533\n",
            "Epoch 719/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4303 - acc: 0.4186 - val_loss: 2.1100 - val_acc: 0.2400\n",
            "Epoch 720/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4295 - acc: 0.4214 - val_loss: 2.1052 - val_acc: 0.2367\n",
            "Epoch 721/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1038 - val_acc: 0.2433\n",
            "Epoch 722/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4286 - acc: 0.4200 - val_loss: 2.1045 - val_acc: 0.2367\n",
            "Epoch 723/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4282 - acc: 0.4214 - val_loss: 2.0911 - val_acc: 0.2400\n",
            "Epoch 724/1000\n",
            "700/700 [==============================] - 0s 400us/step - loss: 1.4281 - acc: 0.4257 - val_loss: 2.1101 - val_acc: 0.2367\n",
            "Epoch 725/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4277 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2433\n",
            "Epoch 726/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4278 - acc: 0.4257 - val_loss: 2.0962 - val_acc: 0.2367\n",
            "Epoch 727/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4273 - acc: 0.4214 - val_loss: 2.1264 - val_acc: 0.2333\n",
            "Epoch 728/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4276 - acc: 0.4200 - val_loss: 2.0961 - val_acc: 0.2400\n",
            "Epoch 729/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4269 - acc: 0.4229 - val_loss: 2.1197 - val_acc: 0.2467\n",
            "Epoch 730/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1247 - val_acc: 0.2400\n",
            "Epoch 731/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4277 - acc: 0.4143 - val_loss: 2.1096 - val_acc: 0.2367\n",
            "Epoch 732/1000\n",
            "700/700 [==============================] - 0s 492us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1076 - val_acc: 0.2400\n",
            "Epoch 733/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.4263 - acc: 0.4286 - val_loss: 2.1008 - val_acc: 0.2400\n",
            "Epoch 734/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4271 - acc: 0.4214 - val_loss: 2.1178 - val_acc: 0.2400\n",
            "Epoch 735/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4261 - acc: 0.4286 - val_loss: 2.1092 - val_acc: 0.2367\n",
            "Epoch 736/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4249 - acc: 0.4300 - val_loss: 2.1022 - val_acc: 0.2400\n",
            "Epoch 737/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4265 - acc: 0.4229 - val_loss: 2.1194 - val_acc: 0.2433\n",
            "Epoch 738/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4265 - acc: 0.4200 - val_loss: 2.1078 - val_acc: 0.2467\n",
            "Epoch 739/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1167 - val_acc: 0.2367\n",
            "Epoch 740/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4250 - acc: 0.4314 - val_loss: 2.1048 - val_acc: 0.2400\n",
            "Epoch 741/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1189 - val_acc: 0.2567\n",
            "Epoch 742/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4252 - acc: 0.4143 - val_loss: 2.1010 - val_acc: 0.2533\n",
            "Epoch 743/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1042 - val_acc: 0.2533\n",
            "Epoch 744/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1045 - val_acc: 0.2433\n",
            "Epoch 745/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1158 - val_acc: 0.2533\n",
            "Epoch 746/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1062 - val_acc: 0.2400\n",
            "Epoch 747/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.4251 - acc: 0.4157 - val_loss: 2.1123 - val_acc: 0.2433\n",
            "Epoch 748/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1289 - val_acc: 0.2600\n",
            "Epoch 749/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0960 - val_acc: 0.2333\n",
            "Epoch 750/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4239 - acc: 0.4329 - val_loss: 2.1004 - val_acc: 0.2300\n",
            "Epoch 751/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4224 - acc: 0.4171 - val_loss: 2.1130 - val_acc: 0.2400\n",
            "Epoch 752/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4233 - acc: 0.4243 - val_loss: 2.1173 - val_acc: 0.2367\n",
            "Epoch 753/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.1337 - val_acc: 0.2333\n",
            "Epoch 754/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4235 - acc: 0.4271 - val_loss: 2.1186 - val_acc: 0.2333\n",
            "Epoch 755/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1169 - val_acc: 0.2467\n",
            "Epoch 756/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1151 - val_acc: 0.2400\n",
            "Epoch 757/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4233 - acc: 0.4200 - val_loss: 2.1210 - val_acc: 0.2433\n",
            "Epoch 758/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4220 - acc: 0.4300 - val_loss: 2.1190 - val_acc: 0.2433\n",
            "Epoch 759/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4221 - acc: 0.4271 - val_loss: 2.1112 - val_acc: 0.2400\n",
            "Epoch 760/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4218 - acc: 0.4329 - val_loss: 2.1117 - val_acc: 0.2400\n",
            "Epoch 761/1000\n",
            "700/700 [==============================] - 0s 398us/step - loss: 1.4215 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2500\n",
            "Epoch 762/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4225 - acc: 0.4257 - val_loss: 2.1261 - val_acc: 0.2400\n",
            "Epoch 763/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4215 - acc: 0.4200 - val_loss: 2.1152 - val_acc: 0.2400\n",
            "Epoch 764/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4227 - acc: 0.4300 - val_loss: 2.1314 - val_acc: 0.2433\n",
            "Epoch 765/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4203 - acc: 0.4214 - val_loss: 2.1405 - val_acc: 0.2333\n",
            "Epoch 766/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4217 - acc: 0.4214 - val_loss: 2.1154 - val_acc: 0.2400\n",
            "Epoch 767/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1160 - val_acc: 0.2367\n",
            "Epoch 768/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1068 - val_acc: 0.2400\n",
            "Epoch 769/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4207 - acc: 0.4243 - val_loss: 2.1165 - val_acc: 0.2367\n",
            "Epoch 770/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4200 - acc: 0.4214 - val_loss: 2.1088 - val_acc: 0.2333\n",
            "Epoch 771/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1229 - val_acc: 0.2367\n",
            "Epoch 772/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4202 - acc: 0.4229 - val_loss: 2.1255 - val_acc: 0.2433\n",
            "Epoch 773/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4200 - acc: 0.4229 - val_loss: 2.1326 - val_acc: 0.2500\n",
            "Epoch 774/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1295 - val_acc: 0.2400\n",
            "Epoch 775/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1295 - val_acc: 0.2533\n",
            "Epoch 776/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
            "Epoch 777/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4177 - acc: 0.4314 - val_loss: 2.1345 - val_acc: 0.2333\n",
            "Epoch 778/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4190 - acc: 0.4214 - val_loss: 2.1203 - val_acc: 0.2333\n",
            "Epoch 779/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4191 - acc: 0.4300 - val_loss: 2.1231 - val_acc: 0.2333\n",
            "Epoch 780/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4190 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2400\n",
            "Epoch 781/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1239 - val_acc: 0.2467\n",
            "Epoch 782/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4184 - acc: 0.4257 - val_loss: 2.1057 - val_acc: 0.2400\n",
            "Epoch 783/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1295 - val_acc: 0.2433\n",
            "Epoch 784/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4181 - acc: 0.4300 - val_loss: 2.1362 - val_acc: 0.2400\n",
            "Epoch 785/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1419 - val_acc: 0.2367\n",
            "Epoch 786/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4180 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
            "Epoch 787/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1135 - val_acc: 0.2500\n",
            "Epoch 788/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2400\n",
            "Epoch 789/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1256 - val_acc: 0.2400\n",
            "Epoch 790/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1284 - val_acc: 0.2400\n",
            "Epoch 791/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2500\n",
            "Epoch 792/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4171 - acc: 0.4229 - val_loss: 2.1204 - val_acc: 0.2367\n",
            "Epoch 793/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4166 - acc: 0.4257 - val_loss: 2.1365 - val_acc: 0.2500\n",
            "Epoch 794/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4169 - acc: 0.4271 - val_loss: 2.1308 - val_acc: 0.2367\n",
            "Epoch 795/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4164 - acc: 0.4314 - val_loss: 2.1278 - val_acc: 0.2400\n",
            "Epoch 796/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4160 - acc: 0.4300 - val_loss: 2.1290 - val_acc: 0.2367\n",
            "Epoch 797/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1355 - val_acc: 0.2367\n",
            "Epoch 798/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4162 - acc: 0.4386 - val_loss: 2.1362 - val_acc: 0.2400\n",
            "Epoch 799/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1291 - val_acc: 0.2567\n",
            "Epoch 800/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4159 - acc: 0.4200 - val_loss: 2.1378 - val_acc: 0.2333\n",
            "Epoch 801/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.2333\n",
            "Epoch 802/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1718 - val_acc: 0.2400\n",
            "Epoch 803/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1338 - val_acc: 0.2600\n",
            "Epoch 804/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1272 - val_acc: 0.2433\n",
            "Epoch 805/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1285 - val_acc: 0.2467\n",
            "Epoch 806/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4148 - acc: 0.4357 - val_loss: 2.1285 - val_acc: 0.2400\n",
            "Epoch 807/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4148 - acc: 0.4386 - val_loss: 2.1343 - val_acc: 0.2500\n",
            "Epoch 808/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4143 - acc: 0.4314 - val_loss: 2.1340 - val_acc: 0.2400\n",
            "Epoch 809/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2467\n",
            "Epoch 810/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4139 - acc: 0.4357 - val_loss: 2.1360 - val_acc: 0.2367\n",
            "Epoch 811/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1368 - val_acc: 0.2400\n",
            "Epoch 812/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4141 - acc: 0.4271 - val_loss: 2.1261 - val_acc: 0.2400\n",
            "Epoch 813/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1430 - val_acc: 0.2400\n",
            "Epoch 814/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4131 - acc: 0.4286 - val_loss: 2.1356 - val_acc: 0.2533\n",
            "Epoch 815/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4139 - acc: 0.4314 - val_loss: 2.1410 - val_acc: 0.2467\n",
            "Epoch 816/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4136 - acc: 0.4300 - val_loss: 2.1348 - val_acc: 0.2367\n",
            "Epoch 817/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4116 - acc: 0.4300 - val_loss: 2.1359 - val_acc: 0.2367\n",
            "Epoch 818/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1431 - val_acc: 0.2367\n",
            "Epoch 819/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4110 - acc: 0.4357 - val_loss: 2.1535 - val_acc: 0.2600\n",
            "Epoch 820/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4131 - acc: 0.4329 - val_loss: 2.1379 - val_acc: 0.2567\n",
            "Epoch 821/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1497 - val_acc: 0.2467\n",
            "Epoch 822/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1381 - val_acc: 0.2367\n",
            "Epoch 823/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.4114 - acc: 0.4271 - val_loss: 2.1430 - val_acc: 0.2433\n",
            "Epoch 824/1000\n",
            "700/700 [==============================] - 0s 482us/step - loss: 1.4110 - acc: 0.4300 - val_loss: 2.1438 - val_acc: 0.2433\n",
            "Epoch 825/1000\n",
            "700/700 [==============================] - 0s 530us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1583 - val_acc: 0.2467\n",
            "Epoch 826/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4122 - acc: 0.4271 - val_loss: 2.1483 - val_acc: 0.2467\n",
            "Epoch 827/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1481 - val_acc: 0.2400\n",
            "Epoch 828/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4118 - acc: 0.4343 - val_loss: 2.1369 - val_acc: 0.2367\n",
            "Epoch 829/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1411 - val_acc: 0.2433\n",
            "Epoch 830/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1457 - val_acc: 0.2400\n",
            "Epoch 831/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 1.4105 - acc: 0.4443 - val_loss: 2.1591 - val_acc: 0.2467\n",
            "Epoch 832/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4111 - acc: 0.4343 - val_loss: 2.1598 - val_acc: 0.2500\n",
            "Epoch 833/1000\n",
            "700/700 [==============================] - 0s 471us/step - loss: 1.4110 - acc: 0.4243 - val_loss: 2.1645 - val_acc: 0.2467\n",
            "Epoch 834/1000\n",
            "700/700 [==============================] - 0s 554us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1743 - val_acc: 0.2433\n",
            "Epoch 835/1000\n",
            "700/700 [==============================] - 0s 506us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2367\n",
            "Epoch 836/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1518 - val_acc: 0.2500\n",
            "Epoch 837/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1380 - val_acc: 0.2433\n",
            "Epoch 838/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1500 - val_acc: 0.2367\n",
            "Epoch 839/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1492 - val_acc: 0.2367\n",
            "Epoch 840/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4081 - acc: 0.4343 - val_loss: 2.1386 - val_acc: 0.2433\n",
            "Epoch 841/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4092 - acc: 0.4371 - val_loss: 2.1470 - val_acc: 0.2367\n",
            "Epoch 842/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1594 - val_acc: 0.2500\n",
            "Epoch 843/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4090 - acc: 0.4314 - val_loss: 2.1468 - val_acc: 0.2367\n",
            "Epoch 844/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4082 - acc: 0.4300 - val_loss: 2.1617 - val_acc: 0.2367\n",
            "Epoch 845/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4088 - acc: 0.4314 - val_loss: 2.1402 - val_acc: 0.2367\n",
            "Epoch 846/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1484 - val_acc: 0.2400\n",
            "Epoch 847/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1584 - val_acc: 0.2433\n",
            "Epoch 848/1000\n",
            "700/700 [==============================] - 0s 555us/step - loss: 1.4079 - acc: 0.4371 - val_loss: 2.1529 - val_acc: 0.2533\n",
            "Epoch 849/1000\n",
            "700/700 [==============================] - 0s 547us/step - loss: 1.4086 - acc: 0.4300 - val_loss: 2.1555 - val_acc: 0.2433\n",
            "Epoch 850/1000\n",
            "700/700 [==============================] - 0s 513us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1484 - val_acc: 0.2367\n",
            "Epoch 851/1000\n",
            "700/700 [==============================] - 0s 566us/step - loss: 1.4071 - acc: 0.4229 - val_loss: 2.1482 - val_acc: 0.2333\n",
            "Epoch 852/1000\n",
            "700/700 [==============================] - 0s 514us/step - loss: 1.4086 - acc: 0.4371 - val_loss: 2.1509 - val_acc: 0.2433\n",
            "Epoch 853/1000\n",
            "700/700 [==============================] - 0s 552us/step - loss: 1.4066 - acc: 0.4329 - val_loss: 2.1501 - val_acc: 0.2367\n",
            "Epoch 854/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4046 - acc: 0.4371 - val_loss: 2.1745 - val_acc: 0.2600\n",
            "Epoch 855/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1510 - val_acc: 0.2333\n",
            "Epoch 856/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4074 - acc: 0.4357 - val_loss: 2.1598 - val_acc: 0.2500\n",
            "Epoch 857/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4067 - acc: 0.4286 - val_loss: 2.1580 - val_acc: 0.2467\n",
            "Epoch 858/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4066 - acc: 0.4343 - val_loss: 2.1567 - val_acc: 0.2367\n",
            "Epoch 859/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1554 - val_acc: 0.2367\n",
            "Epoch 860/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4057 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2533\n",
            "Epoch 861/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4064 - acc: 0.4343 - val_loss: 2.1655 - val_acc: 0.2433\n",
            "Epoch 862/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4071 - acc: 0.4271 - val_loss: 2.1672 - val_acc: 0.2533\n",
            "Epoch 863/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4055 - acc: 0.4329 - val_loss: 2.1677 - val_acc: 0.2500\n",
            "Epoch 864/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1628 - val_acc: 0.2533\n",
            "Epoch 865/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1682 - val_acc: 0.2633\n",
            "Epoch 866/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4049 - acc: 0.4314 - val_loss: 2.1387 - val_acc: 0.2433\n",
            "Epoch 867/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1681 - val_acc: 0.2433\n",
            "Epoch 868/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4054 - acc: 0.4357 - val_loss: 2.1608 - val_acc: 0.2467\n",
            "Epoch 869/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4050 - acc: 0.4386 - val_loss: 2.1594 - val_acc: 0.2400\n",
            "Epoch 870/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4034 - acc: 0.4357 - val_loss: 2.1720 - val_acc: 0.2467\n",
            "Epoch 871/1000\n",
            "700/700 [==============================] - 0s 543us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1759 - val_acc: 0.2467\n",
            "Epoch 872/1000\n",
            "700/700 [==============================] - 0s 542us/step - loss: 1.4037 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2567\n",
            "Epoch 873/1000\n",
            "700/700 [==============================] - 0s 552us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1424 - val_acc: 0.2367\n",
            "Epoch 874/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2367\n",
            "Epoch 875/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4038 - acc: 0.4329 - val_loss: 2.1739 - val_acc: 0.2467\n",
            "Epoch 876/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4035 - acc: 0.4314 - val_loss: 2.1520 - val_acc: 0.2433\n",
            "Epoch 877/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4037 - acc: 0.4271 - val_loss: 2.1733 - val_acc: 0.2367\n",
            "Epoch 878/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2400\n",
            "Epoch 879/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4012 - acc: 0.4371 - val_loss: 2.1696 - val_acc: 0.2400\n",
            "Epoch 880/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4051 - acc: 0.4329 - val_loss: 2.1589 - val_acc: 0.2400\n",
            "Epoch 881/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4035 - acc: 0.4429 - val_loss: 2.1855 - val_acc: 0.2500\n",
            "Epoch 882/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1721 - val_acc: 0.2400\n",
            "Epoch 883/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4044 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2400\n",
            "Epoch 884/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4027 - acc: 0.4314 - val_loss: 2.1799 - val_acc: 0.2533\n",
            "Epoch 885/1000\n",
            "700/700 [==============================] - 0s 397us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1444 - val_acc: 0.2433\n",
            "Epoch 886/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4036 - acc: 0.4386 - val_loss: 2.1664 - val_acc: 0.2467\n",
            "Epoch 887/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4026 - acc: 0.4371 - val_loss: 2.1546 - val_acc: 0.2367\n",
            "Epoch 888/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1653 - val_acc: 0.2400\n",
            "Epoch 889/1000\n",
            "700/700 [==============================] - 0s 401us/step - loss: 1.4010 - acc: 0.4443 - val_loss: 2.1763 - val_acc: 0.2600\n",
            "Epoch 890/1000\n",
            "700/700 [==============================] - 0s 402us/step - loss: 1.4028 - acc: 0.4386 - val_loss: 2.1675 - val_acc: 0.2567\n",
            "Epoch 891/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4024 - acc: 0.4271 - val_loss: 2.1707 - val_acc: 0.2433\n",
            "Epoch 892/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1736 - val_acc: 0.2433\n",
            "Epoch 893/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4018 - acc: 0.4357 - val_loss: 2.1794 - val_acc: 0.2433\n",
            "Epoch 894/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4020 - acc: 0.4429 - val_loss: 2.1670 - val_acc: 0.2400\n",
            "Epoch 895/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4012 - acc: 0.4343 - val_loss: 2.1696 - val_acc: 0.2467\n",
            "Epoch 896/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4014 - acc: 0.4357 - val_loss: 2.1745 - val_acc: 0.2600\n",
            "Epoch 897/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.4017 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2533\n",
            "Epoch 898/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1869 - val_acc: 0.2467\n",
            "Epoch 899/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4015 - acc: 0.4343 - val_loss: 2.1634 - val_acc: 0.2467\n",
            "Epoch 900/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1660 - val_acc: 0.2467\n",
            "Epoch 901/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1780 - val_acc: 0.2533\n",
            "Epoch 902/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4001 - acc: 0.4343 - val_loss: 2.1718 - val_acc: 0.2467\n",
            "Epoch 903/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.3992 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2633\n",
            "Epoch 904/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.3991 - acc: 0.4357 - val_loss: 2.1637 - val_acc: 0.2400\n",
            "Epoch 905/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4010 - acc: 0.4400 - val_loss: 2.1595 - val_acc: 0.2400\n",
            "Epoch 906/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.3998 - acc: 0.4371 - val_loss: 2.1560 - val_acc: 0.2367\n",
            "Epoch 907/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4003 - acc: 0.4386 - val_loss: 2.1815 - val_acc: 0.2467\n",
            "Epoch 908/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1730 - val_acc: 0.2433\n",
            "Epoch 909/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.3993 - acc: 0.4329 - val_loss: 2.1789 - val_acc: 0.2500\n",
            "Epoch 910/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4004 - acc: 0.4357 - val_loss: 2.1613 - val_acc: 0.2400\n",
            "Epoch 911/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.3991 - acc: 0.4371 - val_loss: 2.1790 - val_acc: 0.2367\n",
            "Epoch 912/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.3995 - acc: 0.4400 - val_loss: 2.1687 - val_acc: 0.2367\n",
            "Epoch 913/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4000 - acc: 0.4371 - val_loss: 2.1881 - val_acc: 0.2433\n",
            "Epoch 914/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1862 - val_acc: 0.2567\n",
            "Epoch 915/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2467\n",
            "Epoch 916/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.3987 - acc: 0.4386 - val_loss: 2.1795 - val_acc: 0.2400\n",
            "Epoch 917/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.3978 - acc: 0.4400 - val_loss: 2.1797 - val_acc: 0.2400\n",
            "Epoch 918/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.3970 - acc: 0.4386 - val_loss: 2.1789 - val_acc: 0.2533\n",
            "Epoch 919/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.3984 - acc: 0.4329 - val_loss: 2.1871 - val_acc: 0.2433\n",
            "Epoch 920/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1695 - val_acc: 0.2500\n",
            "Epoch 921/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.3984 - acc: 0.4357 - val_loss: 2.1721 - val_acc: 0.2400\n",
            "Epoch 922/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.3967 - acc: 0.4400 - val_loss: 2.1838 - val_acc: 0.2500\n",
            "Epoch 923/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1709 - val_acc: 0.2567\n",
            "Epoch 924/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1766 - val_acc: 0.2467\n",
            "Epoch 925/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1822 - val_acc: 0.2367\n",
            "Epoch 926/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.3972 - acc: 0.4443 - val_loss: 2.1771 - val_acc: 0.2467\n",
            "Epoch 927/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1778 - val_acc: 0.2400\n",
            "Epoch 928/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.3971 - acc: 0.4400 - val_loss: 2.1921 - val_acc: 0.2433\n",
            "Epoch 929/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1917 - val_acc: 0.2400\n",
            "Epoch 930/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.3971 - acc: 0.4357 - val_loss: 2.1789 - val_acc: 0.2467\n",
            "Epoch 931/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.3967 - acc: 0.4329 - val_loss: 2.1803 - val_acc: 0.2467\n",
            "Epoch 932/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1716 - val_acc: 0.2500\n",
            "Epoch 933/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1818 - val_acc: 0.2467\n",
            "Epoch 934/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.3958 - acc: 0.4414 - val_loss: 2.1874 - val_acc: 0.2500\n",
            "Epoch 935/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.3966 - acc: 0.4414 - val_loss: 2.1846 - val_acc: 0.2500\n",
            "Epoch 936/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.3965 - acc: 0.4429 - val_loss: 2.1883 - val_acc: 0.2500\n",
            "Epoch 937/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.3960 - acc: 0.4400 - val_loss: 2.1831 - val_acc: 0.2367\n",
            "Epoch 938/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.3953 - acc: 0.4443 - val_loss: 2.1899 - val_acc: 0.2500\n",
            "Epoch 939/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2500\n",
            "Epoch 940/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1790 - val_acc: 0.2400\n",
            "Epoch 941/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.3957 - acc: 0.4343 - val_loss: 2.1841 - val_acc: 0.2400\n",
            "Epoch 942/1000\n",
            "700/700 [==============================] - 0s 408us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1692 - val_acc: 0.2333\n",
            "Epoch 943/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1922 - val_acc: 0.2433\n",
            "Epoch 944/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.3944 - acc: 0.4371 - val_loss: 2.1942 - val_acc: 0.2433\n",
            "Epoch 945/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2500\n",
            "Epoch 946/1000\n",
            "700/700 [==============================] - 0s 508us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1833 - val_acc: 0.2467\n",
            "Epoch 947/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1935 - val_acc: 0.2533\n",
            "Epoch 948/1000\n",
            "700/700 [==============================] - 0s 405us/step - loss: 1.3940 - acc: 0.4300 - val_loss: 2.1744 - val_acc: 0.2367\n",
            "Epoch 949/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.3938 - acc: 0.4471 - val_loss: 2.1834 - val_acc: 0.2400\n",
            "Epoch 950/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2367\n",
            "Epoch 951/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
            "Epoch 952/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1852 - val_acc: 0.2467\n",
            "Epoch 953/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.3935 - acc: 0.4371 - val_loss: 2.1988 - val_acc: 0.2533\n",
            "Epoch 954/1000\n",
            "700/700 [==============================] - 0s 550us/step - loss: 1.3940 - acc: 0.4471 - val_loss: 2.1858 - val_acc: 0.2567\n",
            "Epoch 955/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.3936 - acc: 0.4429 - val_loss: 2.1951 - val_acc: 0.2500\n",
            "Epoch 956/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.2024 - val_acc: 0.2433\n",
            "Epoch 957/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2433\n",
            "Epoch 958/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2130 - val_acc: 0.2467\n",
            "Epoch 959/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.3936 - acc: 0.4414 - val_loss: 2.1808 - val_acc: 0.2467\n",
            "Epoch 960/1000\n",
            "700/700 [==============================] - 0s 520us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1918 - val_acc: 0.2467\n",
            "Epoch 961/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1688 - val_acc: 0.2467\n",
            "Epoch 962/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.3931 - acc: 0.4400 - val_loss: 2.1895 - val_acc: 0.2467\n",
            "Epoch 963/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3926 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2500\n",
            "Epoch 964/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.3919 - acc: 0.4357 - val_loss: 2.1782 - val_acc: 0.2433\n",
            "Epoch 965/1000\n",
            "700/700 [==============================] - 0s 535us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1849 - val_acc: 0.2533\n",
            "Epoch 966/1000\n",
            "700/700 [==============================] - 0s 548us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1969 - val_acc: 0.2567\n",
            "Epoch 967/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1947 - val_acc: 0.2467\n",
            "Epoch 968/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1865 - val_acc: 0.2433\n",
            "Epoch 969/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.3917 - acc: 0.4414 - val_loss: 2.1907 - val_acc: 0.2433\n",
            "Epoch 970/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.3916 - acc: 0.4400 - val_loss: 2.2006 - val_acc: 0.2400\n",
            "Epoch 971/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2467\n",
            "Epoch 972/1000\n",
            "700/700 [==============================] - 0s 447us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.2011 - val_acc: 0.2333\n",
            "Epoch 973/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.3901 - acc: 0.4400 - val_loss: 2.1959 - val_acc: 0.2500\n",
            "Epoch 974/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.3908 - acc: 0.4386 - val_loss: 2.1971 - val_acc: 0.2500\n",
            "Epoch 975/1000\n",
            "700/700 [==============================] - 0s 478us/step - loss: 1.3907 - acc: 0.4443 - val_loss: 2.2058 - val_acc: 0.2500\n",
            "Epoch 976/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2500\n",
            "Epoch 977/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.3905 - acc: 0.4343 - val_loss: 2.1915 - val_acc: 0.2400\n",
            "Epoch 978/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.3904 - acc: 0.4486 - val_loss: 2.1936 - val_acc: 0.2533\n",
            "Epoch 979/1000\n",
            "700/700 [==============================] - 0s 496us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2467\n",
            "Epoch 980/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
            "Epoch 981/1000\n",
            "700/700 [==============================] - 0s 487us/step - loss: 1.3894 - acc: 0.4371 - val_loss: 2.2124 - val_acc: 0.2500\n",
            "Epoch 982/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.3902 - acc: 0.4400 - val_loss: 2.1965 - val_acc: 0.2533\n",
            "Epoch 983/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.3897 - acc: 0.4357 - val_loss: 2.2004 - val_acc: 0.2500\n",
            "Epoch 984/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
            "Epoch 985/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.3891 - acc: 0.4400 - val_loss: 2.2033 - val_acc: 0.2367\n",
            "Epoch 986/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.3891 - acc: 0.4414 - val_loss: 2.2010 - val_acc: 0.2500\n",
            "Epoch 987/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.3887 - acc: 0.4414 - val_loss: 2.1880 - val_acc: 0.2400\n",
            "Epoch 988/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.3886 - acc: 0.4429 - val_loss: 2.2116 - val_acc: 0.2633\n",
            "Epoch 989/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3903 - acc: 0.4357 - val_loss: 2.2104 - val_acc: 0.2533\n",
            "Epoch 990/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.3887 - acc: 0.4443 - val_loss: 2.2221 - val_acc: 0.2533\n",
            "Epoch 991/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.3890 - acc: 0.4471 - val_loss: 2.1938 - val_acc: 0.2433\n",
            "Epoch 992/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2048 - val_acc: 0.2400\n",
            "Epoch 993/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.3885 - acc: 0.4457 - val_loss: 2.2089 - val_acc: 0.2533\n",
            "Epoch 994/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.3885 - acc: 0.4357 - val_loss: 2.1919 - val_acc: 0.2367\n",
            "Epoch 995/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.3890 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
            "Epoch 996/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.3877 - acc: 0.4457 - val_loss: 2.2035 - val_acc: 0.2467\n",
            "Epoch 997/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.3879 - acc: 0.4429 - val_loss: 2.2026 - val_acc: 0.2533\n",
            "Epoch 998/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.3887 - acc: 0.4386 - val_loss: 2.2113 - val_acc: 0.2533\n",
            "Epoch 999/1000\n",
            "700/700 [==============================] - 0s 498us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2500\n",
            "Epoch 1000/1000\n",
            "700/700 [==============================] - 0s 535us/step - loss: 1.3879 - acc: 0.4386 - val_loss: 2.2080 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEGCAYAAAAwpAFeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KBVX3AcVMLl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36053
        },
        "outputId": "3fbeefa5-60dc-4d14-84dd-67861fb0b456"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "# 1. 데이터셋 준비하기\n",
        "\n",
        "# 훈련셋과 시험셋 로딩\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "# 훈련셋과 검증셋 분리\n",
        "X_val = X_train[50000:]\n",
        "Y_val = Y_train[50000:]\n",
        "X_train = X_train[:50000]\n",
        "Y_train = Y_train[:50000]\n",
        "\n",
        "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
        "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "\n",
        "# 훈련셋, 검증셋 고르기\n",
        "train_rand_idxs = np.random.choice(50000, 700)\n",
        "val_rand_idxs = np.random.choice(10000, 300)\n",
        "\n",
        "X_train = X_train[train_rand_idxs]\n",
        "Y_train = Y_train[train_rand_idxs]\n",
        "X_val = X_val[val_rand_idxs]\n",
        "Y_val = Y_val[val_rand_idxs]\n",
        "\n",
        "# 라벨링 전환\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_val = np_utils.to_categorical(Y_val)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# 3. 모델 엮기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val), callbacks=[tb_hist])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 700 samples, validate on 300 samples\n",
            "Epoch 1/1000\n",
            "700/700 [==============================] - 0s 590us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
            "Epoch 2/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
            "Epoch 3/1000\n",
            "700/700 [==============================] - 0s 487us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
            "Epoch 4/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
            "Epoch 5/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
            "Epoch 6/1000\n",
            "700/700 [==============================] - 0s 351us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
            "Epoch 7/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
            "Epoch 8/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
            "Epoch 9/1000\n",
            "700/700 [==============================] - 0s 508us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
            "Epoch 10/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
            "Epoch 11/1000\n",
            "700/700 [==============================] - 0s 490us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
            "Epoch 12/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
            "Epoch 13/1000\n",
            "700/700 [==============================] - 0s 513us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
            "Epoch 14/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
            "Epoch 15/1000\n",
            "700/700 [==============================] - 0s 503us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
            "Epoch 16/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
            "Epoch 17/1000\n",
            "700/700 [==============================] - 0s 491us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
            "Epoch 18/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
            "Epoch 19/1000\n",
            "700/700 [==============================] - 0s 519us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
            "Epoch 20/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
            "Epoch 21/1000\n",
            "700/700 [==============================] - 0s 490us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
            "Epoch 22/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
            "Epoch 23/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
            "Epoch 24/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
            "Epoch 25/1000\n",
            "700/700 [==============================] - 0s 486us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
            "Epoch 26/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
            "Epoch 27/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
            "Epoch 28/1000\n",
            "700/700 [==============================] - 0s 504us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
            "Epoch 29/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
            "Epoch 30/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
            "Epoch 31/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
            "Epoch 32/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
            "Epoch 33/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
            "Epoch 34/1000\n",
            "700/700 [==============================] - 0s 511us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
            "Epoch 35/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
            "Epoch 36/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
            "Epoch 37/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
            "Epoch 38/1000\n",
            "700/700 [==============================] - 0s 525us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
            "Epoch 39/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
            "Epoch 40/1000\n",
            "700/700 [==============================] - 0s 497us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
            "Epoch 41/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
            "Epoch 42/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
            "Epoch 43/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
            "Epoch 44/1000\n",
            "700/700 [==============================] - 0s 521us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
            "Epoch 45/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
            "Epoch 46/1000\n",
            "700/700 [==============================] - 0s 490us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
            "Epoch 47/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
            "Epoch 48/1000\n",
            "700/700 [==============================] - 0s 499us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
            "Epoch 49/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
            "Epoch 50/1000\n",
            "700/700 [==============================] - 0s 499us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
            "Epoch 51/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
            "Epoch 52/1000\n",
            "700/700 [==============================] - 0s 493us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
            "Epoch 53/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
            "Epoch 54/1000\n",
            "700/700 [==============================] - 0s 488us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
            "Epoch 55/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
            "Epoch 56/1000\n",
            "700/700 [==============================] - 0s 506us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
            "Epoch 57/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
            "Epoch 58/1000\n",
            "700/700 [==============================] - 0s 482us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
            "Epoch 59/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
            "Epoch 60/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
            "Epoch 61/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
            "Epoch 62/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
            "Epoch 63/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
            "Epoch 64/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
            "Epoch 65/1000\n",
            "700/700 [==============================] - 0s 515us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
            "Epoch 66/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
            "Epoch 67/1000\n",
            "700/700 [==============================] - 0s 512us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
            "Epoch 68/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
            "Epoch 69/1000\n",
            "700/700 [==============================] - 0s 517us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
            "Epoch 70/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
            "Epoch 71/1000\n",
            "700/700 [==============================] - 0s 504us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
            "Epoch 72/1000\n",
            "700/700 [==============================] - 0s 509us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
            "Epoch 73/1000\n",
            "700/700 [==============================] - 0s 483us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
            "Epoch 74/1000\n",
            "700/700 [==============================] - 0s 491us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
            "Epoch 75/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
            "Epoch 76/1000\n",
            "700/700 [==============================] - 0s 493us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
            "Epoch 77/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
            "Epoch 78/1000\n",
            "700/700 [==============================] - 0s 507us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
            "Epoch 79/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
            "Epoch 80/1000\n",
            "700/700 [==============================] - 0s 492us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
            "Epoch 81/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
            "Epoch 82/1000\n",
            "700/700 [==============================] - 0s 501us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
            "Epoch 83/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
            "Epoch 84/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
            "Epoch 85/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
            "Epoch 86/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
            "Epoch 87/1000\n",
            "700/700 [==============================] - 0s 495us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
            "Epoch 88/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
            "Epoch 89/1000\n",
            "700/700 [==============================] - 0s 502us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
            "Epoch 90/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
            "Epoch 91/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
            "Epoch 92/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
            "Epoch 93/1000\n",
            "700/700 [==============================] - 0s 511us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
            "Epoch 94/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
            "Epoch 95/1000\n",
            "700/700 [==============================] - 0s 474us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
            "Epoch 96/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
            "Epoch 97/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
            "Epoch 98/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
            "Epoch 99/1000\n",
            "700/700 [==============================] - 0s 498us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
            "Epoch 100/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
            "Epoch 101/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
            "Epoch 102/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
            "Epoch 103/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
            "Epoch 104/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
            "Epoch 105/1000\n",
            "700/700 [==============================] - 0s 484us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
            "Epoch 106/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
            "Epoch 107/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
            "Epoch 108/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
            "Epoch 109/1000\n",
            "700/700 [==============================] - 0s 499us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
            "Epoch 110/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
            "Epoch 111/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
            "Epoch 112/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
            "Epoch 113/1000\n",
            "700/700 [==============================] - 0s 475us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
            "Epoch 114/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
            "Epoch 115/1000\n",
            "700/700 [==============================] - 0s 486us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
            "Epoch 116/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
            "Epoch 117/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
            "Epoch 118/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
            "Epoch 119/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n",
            "Epoch 120/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
            "Epoch 121/1000\n",
            "700/700 [==============================] - 0s 482us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
            "Epoch 122/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
            "Epoch 123/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
            "Epoch 124/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
            "Epoch 125/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
            "Epoch 126/1000\n",
            "700/700 [==============================] - 0s 481us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
            "Epoch 127/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
            "Epoch 128/1000\n",
            "700/700 [==============================] - 0s 494us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
            "Epoch 129/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
            "Epoch 130/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
            "Epoch 131/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
            "Epoch 132/1000\n",
            "700/700 [==============================] - 0s 481us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
            "Epoch 133/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
            "Epoch 134/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
            "Epoch 135/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
            "Epoch 136/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
            "Epoch 137/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
            "Epoch 138/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
            "Epoch 139/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
            "Epoch 140/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
            "Epoch 141/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
            "Epoch 142/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
            "Epoch 143/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
            "Epoch 144/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
            "Epoch 145/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
            "Epoch 146/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
            "Epoch 147/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
            "Epoch 148/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
            "Epoch 149/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
            "Epoch 150/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
            "Epoch 151/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
            "Epoch 152/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
            "Epoch 153/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
            "Epoch 154/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
            "Epoch 155/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
            "Epoch 156/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
            "Epoch 157/1000\n",
            "700/700 [==============================] - 0s 481us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
            "Epoch 158/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
            "Epoch 159/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
            "Epoch 160/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
            "Epoch 161/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
            "Epoch 162/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
            "Epoch 163/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
            "Epoch 164/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
            "Epoch 165/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
            "Epoch 166/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
            "Epoch 167/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
            "Epoch 168/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
            "Epoch 169/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
            "Epoch 170/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
            "Epoch 171/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
            "Epoch 172/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
            "Epoch 173/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
            "Epoch 174/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
            "Epoch 175/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
            "Epoch 176/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
            "Epoch 177/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
            "Epoch 178/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
            "Epoch 179/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
            "Epoch 180/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
            "Epoch 181/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
            "Epoch 182/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
            "Epoch 183/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
            "Epoch 184/1000\n",
            "700/700 [==============================] - 0s 488us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
            "Epoch 185/1000\n",
            "700/700 [==============================] - 0s 511us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
            "Epoch 186/1000\n",
            "700/700 [==============================] - 0s 493us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
            "Epoch 187/1000\n",
            "700/700 [==============================] - 0s 500us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
            "Epoch 188/1000\n",
            "700/700 [==============================] - 0s 501us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
            "Epoch 189/1000\n",
            "700/700 [==============================] - 0s 510us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
            "Epoch 190/1000\n",
            "700/700 [==============================] - 0s 485us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
            "Epoch 191/1000\n",
            "700/700 [==============================] - 0s 485us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
            "Epoch 192/1000\n",
            "700/700 [==============================] - 0s 524us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
            "Epoch 193/1000\n",
            "700/700 [==============================] - 0s 497us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
            "Epoch 194/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
            "Epoch 195/1000\n",
            "700/700 [==============================] - 0s 504us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
            "Epoch 196/1000\n",
            "700/700 [==============================] - 0s 490us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
            "Epoch 197/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
            "Epoch 198/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
            "Epoch 199/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
            "Epoch 200/1000\n",
            "700/700 [==============================] - 0s 491us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
            "Epoch 201/1000\n",
            "700/700 [==============================] - 0s 442us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
            "Epoch 202/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
            "Epoch 203/1000\n",
            "700/700 [==============================] - 0s 474us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
            "Epoch 204/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
            "Epoch 205/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
            "Epoch 206/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
            "Epoch 207/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
            "Epoch 208/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
            "Epoch 209/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
            "Epoch 210/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
            "Epoch 211/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
            "Epoch 212/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
            "Epoch 213/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
            "Epoch 214/1000\n",
            "700/700 [==============================] - 0s 486us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
            "Epoch 215/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
            "Epoch 216/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
            "Epoch 217/1000\n",
            "700/700 [==============================] - 0s 494us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
            "Epoch 218/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
            "Epoch 219/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
            "Epoch 220/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
            "Epoch 221/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
            "Epoch 222/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
            "Epoch 223/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
            "Epoch 224/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
            "Epoch 225/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
            "Epoch 226/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
            "Epoch 227/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
            "Epoch 228/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
            "Epoch 229/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
            "Epoch 230/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
            "Epoch 231/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8605 - val_acc: 0.2200\n",
            "Epoch 232/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8730 - val_acc: 0.2133\n",
            "Epoch 233/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
            "Epoch 234/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
            "Epoch 235/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
            "Epoch 236/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
            "Epoch 237/1000\n",
            "700/700 [==============================] - 0s 442us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
            "Epoch 238/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
            "Epoch 239/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
            "Epoch 240/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
            "Epoch 241/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
            "Epoch 242/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
            "Epoch 243/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
            "Epoch 244/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
            "Epoch 245/1000\n",
            "700/700 [==============================] - 0s 644us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8838 - val_acc: 0.2233\n",
            "Epoch 246/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
            "Epoch 247/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
            "Epoch 248/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
            "Epoch 249/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
            "Epoch 250/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
            "Epoch 251/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
            "Epoch 252/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
            "Epoch 253/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
            "Epoch 254/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
            "Epoch 255/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
            "Epoch 256/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
            "Epoch 257/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
            "Epoch 258/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
            "Epoch 259/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
            "Epoch 260/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
            "Epoch 261/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
            "Epoch 262/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
            "Epoch 263/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
            "Epoch 264/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
            "Epoch 265/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
            "Epoch 266/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
            "Epoch 267/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8918 - val_acc: 0.2300\n",
            "Epoch 268/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
            "Epoch 269/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
            "Epoch 270/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
            "Epoch 271/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
            "Epoch 272/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
            "Epoch 273/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
            "Epoch 274/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
            "Epoch 275/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
            "Epoch 276/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
            "Epoch 277/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
            "Epoch 278/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
            "Epoch 279/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
            "Epoch 280/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
            "Epoch 281/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
            "Epoch 282/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
            "Epoch 283/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
            "Epoch 284/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
            "Epoch 285/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
            "Epoch 286/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
            "Epoch 287/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
            "Epoch 288/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
            "Epoch 289/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
            "Epoch 290/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
            "Epoch 291/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
            "Epoch 292/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
            "Epoch 293/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
            "Epoch 294/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
            "Epoch 295/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
            "Epoch 296/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
            "Epoch 297/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
            "Epoch 298/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
            "Epoch 299/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
            "Epoch 300/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
            "Epoch 301/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.5469 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
            "Epoch 302/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
            "Epoch 303/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.5464 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
            "Epoch 304/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
            "Epoch 305/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.5432 - acc: 0.3643 - val_loss: 1.9140 - val_acc: 0.2267\n",
            "Epoch 306/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.5458 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2233\n",
            "Epoch 307/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.5436 - acc: 0.3671 - val_loss: 1.9064 - val_acc: 0.2267\n",
            "Epoch 308/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9129 - val_acc: 0.2333\n",
            "Epoch 309/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5435 - acc: 0.3643 - val_loss: 1.9120 - val_acc: 0.2367\n",
            "Epoch 310/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5448 - acc: 0.3671 - val_loss: 1.9110 - val_acc: 0.2167\n",
            "Epoch 311/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.5426 - acc: 0.3586 - val_loss: 1.9058 - val_acc: 0.2300\n",
            "Epoch 312/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9273 - val_acc: 0.2367\n",
            "Epoch 313/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9056 - val_acc: 0.2633\n",
            "Epoch 314/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5433 - acc: 0.3686 - val_loss: 1.9131 - val_acc: 0.2300\n",
            "Epoch 315/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9118 - val_acc: 0.2233\n",
            "Epoch 316/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5404 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2233\n",
            "Epoch 317/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9213 - val_acc: 0.2333\n",
            "Epoch 318/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9096 - val_acc: 0.2300\n",
            "Epoch 319/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9092 - val_acc: 0.2300\n",
            "Epoch 320/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9278 - val_acc: 0.2233\n",
            "Epoch 321/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9258 - val_acc: 0.2300\n",
            "Epoch 322/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9181 - val_acc: 0.2533\n",
            "Epoch 323/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9197 - val_acc: 0.2300\n",
            "Epoch 324/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.5373 - acc: 0.3657 - val_loss: 1.9227 - val_acc: 0.2200\n",
            "Epoch 325/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5387 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2133\n",
            "Epoch 326/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5365 - acc: 0.3614 - val_loss: 1.9227 - val_acc: 0.2200\n",
            "Epoch 327/1000\n",
            "700/700 [==============================] - 0s 403us/step - loss: 1.5359 - acc: 0.3743 - val_loss: 1.9378 - val_acc: 0.2333\n",
            "Epoch 328/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9307 - val_acc: 0.2233\n",
            "Epoch 329/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5354 - acc: 0.3714 - val_loss: 1.9147 - val_acc: 0.2300\n",
            "Epoch 330/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.5351 - acc: 0.3600 - val_loss: 1.9222 - val_acc: 0.2333\n",
            "Epoch 331/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5338 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2200\n",
            "Epoch 332/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.5346 - acc: 0.3571 - val_loss: 1.9340 - val_acc: 0.2500\n",
            "Epoch 333/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5358 - acc: 0.3671 - val_loss: 1.9234 - val_acc: 0.2233\n",
            "Epoch 334/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9289 - val_acc: 0.2233\n",
            "Epoch 335/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5327 - acc: 0.3757 - val_loss: 1.9246 - val_acc: 0.2567\n",
            "Epoch 336/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.5335 - acc: 0.3786 - val_loss: 1.9184 - val_acc: 0.2300\n",
            "Epoch 337/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5330 - acc: 0.3757 - val_loss: 1.9324 - val_acc: 0.2300\n",
            "Epoch 338/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9238 - val_acc: 0.2133\n",
            "Epoch 339/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9157 - val_acc: 0.2167\n",
            "Epoch 340/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9403 - val_acc: 0.2267\n",
            "Epoch 341/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.5317 - acc: 0.3757 - val_loss: 1.9258 - val_acc: 0.2267\n",
            "Epoch 342/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9441 - val_acc: 0.2167\n",
            "Epoch 343/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.5310 - acc: 0.3686 - val_loss: 1.9333 - val_acc: 0.2267\n",
            "Epoch 344/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9431 - val_acc: 0.2300\n",
            "Epoch 345/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9443 - val_acc: 0.2567\n",
            "Epoch 346/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9314 - val_acc: 0.2267\n",
            "Epoch 347/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.5277 - acc: 0.3800 - val_loss: 1.9199 - val_acc: 0.2200\n",
            "Epoch 348/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2167\n",
            "Epoch 349/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9273 - val_acc: 0.2133\n",
            "Epoch 350/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
            "Epoch 351/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9309 - val_acc: 0.2333\n",
            "Epoch 352/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
            "Epoch 353/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2300\n",
            "Epoch 354/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.5279 - acc: 0.3700 - val_loss: 1.9350 - val_acc: 0.2167\n",
            "Epoch 355/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9553 - val_acc: 0.2267\n",
            "Epoch 356/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9442 - val_acc: 0.2433\n",
            "Epoch 357/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5259 - acc: 0.3743 - val_loss: 1.9355 - val_acc: 0.2267\n",
            "Epoch 358/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9494 - val_acc: 0.2233\n",
            "Epoch 359/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9450 - val_acc: 0.2133\n",
            "Epoch 360/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9454 - val_acc: 0.2233\n",
            "Epoch 361/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9485 - val_acc: 0.2300\n",
            "Epoch 362/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5240 - acc: 0.3643 - val_loss: 1.9508 - val_acc: 0.2267\n",
            "Epoch 363/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.5215 - acc: 0.3757 - val_loss: 1.9527 - val_acc: 0.2333\n",
            "Epoch 364/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9381 - val_acc: 0.2300\n",
            "Epoch 365/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9524 - val_acc: 0.2267\n",
            "Epoch 366/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5222 - acc: 0.3686 - val_loss: 1.9406 - val_acc: 0.2133\n",
            "Epoch 367/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.5221 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2300\n",
            "Epoch 368/1000\n",
            "700/700 [==============================] - 0s 447us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9551 - val_acc: 0.2367\n",
            "Epoch 369/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5207 - acc: 0.3629 - val_loss: 1.9321 - val_acc: 0.2367\n",
            "Epoch 370/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9534 - val_acc: 0.2400\n",
            "Epoch 371/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9508 - val_acc: 0.2233\n",
            "Epoch 372/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9590 - val_acc: 0.2333\n",
            "Epoch 373/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
            "Epoch 374/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9514 - val_acc: 0.2267\n",
            "Epoch 375/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9386 - val_acc: 0.2267\n",
            "Epoch 376/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5182 - acc: 0.3800 - val_loss: 1.9487 - val_acc: 0.2167\n",
            "Epoch 377/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9760 - val_acc: 0.2267\n",
            "Epoch 378/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2367\n",
            "Epoch 379/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9516 - val_acc: 0.2367\n",
            "Epoch 380/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9602 - val_acc: 0.2567\n",
            "Epoch 381/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9711 - val_acc: 0.2167\n",
            "Epoch 382/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9585 - val_acc: 0.2267\n",
            "Epoch 383/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9714 - val_acc: 0.2433\n",
            "Epoch 384/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9509 - val_acc: 0.2233\n",
            "Epoch 385/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9579 - val_acc: 0.2267\n",
            "Epoch 386/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9502 - val_acc: 0.2333\n",
            "Epoch 387/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9578 - val_acc: 0.2300\n",
            "Epoch 388/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9668 - val_acc: 0.2467\n",
            "Epoch 389/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5158 - acc: 0.3800 - val_loss: 1.9490 - val_acc: 0.2267\n",
            "Epoch 390/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9572 - val_acc: 0.2400\n",
            "Epoch 391/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9539 - val_acc: 0.2367\n",
            "Epoch 392/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9599 - val_acc: 0.2233\n",
            "Epoch 393/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.5137 - acc: 0.3757 - val_loss: 1.9730 - val_acc: 0.2233\n",
            "Epoch 394/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9565 - val_acc: 0.2267\n",
            "Epoch 395/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.5132 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2167\n",
            "Epoch 396/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.5124 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
            "Epoch 397/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.5111 - acc: 0.3857 - val_loss: 1.9755 - val_acc: 0.2367\n",
            "Epoch 398/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9588 - val_acc: 0.2200\n",
            "Epoch 399/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9872 - val_acc: 0.2333\n",
            "Epoch 400/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9599 - val_acc: 0.2167\n",
            "Epoch 401/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
            "Epoch 402/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9650 - val_acc: 0.2233\n",
            "Epoch 403/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2200\n",
            "Epoch 404/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9678 - val_acc: 0.2333\n",
            "Epoch 405/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9811 - val_acc: 0.2300\n",
            "Epoch 406/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9745 - val_acc: 0.2200\n",
            "Epoch 407/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9792 - val_acc: 0.2267\n",
            "Epoch 408/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9706 - val_acc: 0.2267\n",
            "Epoch 409/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9783 - val_acc: 0.2367\n",
            "Epoch 410/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9611 - val_acc: 0.2267\n",
            "Epoch 411/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
            "Epoch 412/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9719 - val_acc: 0.2233\n",
            "Epoch 413/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9760 - val_acc: 0.2333\n",
            "Epoch 414/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.5043 - acc: 0.3786 - val_loss: 1.9842 - val_acc: 0.2333\n",
            "Epoch 415/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9778 - val_acc: 0.2333\n",
            "Epoch 416/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9889 - val_acc: 0.2267\n",
            "Epoch 417/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9804 - val_acc: 0.2200\n",
            "Epoch 418/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2333\n",
            "Epoch 419/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9663 - val_acc: 0.2200\n",
            "Epoch 420/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
            "Epoch 421/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.5011 - acc: 0.3829 - val_loss: 1.9692 - val_acc: 0.2433\n",
            "Epoch 422/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.5004 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
            "Epoch 423/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2333\n",
            "Epoch 424/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9678 - val_acc: 0.2200\n",
            "Epoch 425/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9619 - val_acc: 0.2400\n",
            "Epoch 426/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
            "Epoch 427/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9833 - val_acc: 0.2533\n",
            "Epoch 428/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
            "Epoch 429/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9696 - val_acc: 0.2300\n",
            "Epoch 430/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4977 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2467\n",
            "Epoch 431/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4990 - acc: 0.3786 - val_loss: 1.9880 - val_acc: 0.2333\n",
            "Epoch 432/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2233\n",
            "Epoch 433/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4967 - acc: 0.3814 - val_loss: 1.9850 - val_acc: 0.2367\n",
            "Epoch 434/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4976 - acc: 0.3743 - val_loss: 1.9881 - val_acc: 0.2233\n",
            "Epoch 435/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4957 - acc: 0.3900 - val_loss: 1.9819 - val_acc: 0.2267\n",
            "Epoch 436/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9691 - val_acc: 0.2233\n",
            "Epoch 437/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4957 - acc: 0.3943 - val_loss: 1.9951 - val_acc: 0.2200\n",
            "Epoch 438/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9635 - val_acc: 0.2300\n",
            "Epoch 439/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4946 - acc: 0.3771 - val_loss: 1.9781 - val_acc: 0.2233\n",
            "Epoch 440/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4960 - acc: 0.3800 - val_loss: 1.9796 - val_acc: 0.2300\n",
            "Epoch 441/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9825 - val_acc: 0.2300\n",
            "Epoch 442/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4944 - acc: 0.3829 - val_loss: 1.9939 - val_acc: 0.2233\n",
            "Epoch 443/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9899 - val_acc: 0.2400\n",
            "Epoch 444/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4946 - acc: 0.3829 - val_loss: 1.9926 - val_acc: 0.2233\n",
            "Epoch 445/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 1.9955 - val_acc: 0.2300\n",
            "Epoch 446/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4931 - acc: 0.3886 - val_loss: 2.0029 - val_acc: 0.2267\n",
            "Epoch 447/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4926 - acc: 0.3800 - val_loss: 2.0142 - val_acc: 0.2300\n",
            "Epoch 448/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9924 - val_acc: 0.2267\n",
            "Epoch 449/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0006 - val_acc: 0.2333\n",
            "Epoch 450/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2233\n",
            "Epoch 451/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9986 - val_acc: 0.2233\n",
            "Epoch 452/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
            "Epoch 453/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2333\n",
            "Epoch 454/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9967 - val_acc: 0.2333\n",
            "Epoch 455/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9881 - val_acc: 0.2233\n",
            "Epoch 456/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
            "Epoch 457/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9972 - val_acc: 0.2333\n",
            "Epoch 458/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9926 - val_acc: 0.2267\n",
            "Epoch 459/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9909 - val_acc: 0.2433\n",
            "Epoch 460/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0007 - val_acc: 0.2300\n",
            "Epoch 461/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0033 - val_acc: 0.2300\n",
            "Epoch 462/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9937 - val_acc: 0.2267\n",
            "Epoch 463/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4872 - acc: 0.3857 - val_loss: 2.0002 - val_acc: 0.2467\n",
            "Epoch 464/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 1.9888 - val_acc: 0.2333\n",
            "Epoch 465/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9972 - val_acc: 0.2233\n",
            "Epoch 466/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0004 - val_acc: 0.2267\n",
            "Epoch 467/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2300\n",
            "Epoch 468/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9905 - val_acc: 0.2267\n",
            "Epoch 469/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0313 - val_acc: 0.2333\n",
            "Epoch 470/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 2.0096 - val_acc: 0.2233\n",
            "Epoch 471/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4859 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2267\n",
            "Epoch 472/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4845 - acc: 0.3971 - val_loss: 2.0080 - val_acc: 0.2367\n",
            "Epoch 473/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4850 - acc: 0.3914 - val_loss: 2.0121 - val_acc: 0.2367\n",
            "Epoch 474/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9976 - val_acc: 0.2267\n",
            "Epoch 475/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0047 - val_acc: 0.2233\n",
            "Epoch 476/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4835 - acc: 0.3900 - val_loss: 2.0056 - val_acc: 0.2267\n",
            "Epoch 477/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0095 - val_acc: 0.2267\n",
            "Epoch 478/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0056 - val_acc: 0.2333\n",
            "Epoch 479/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4833 - acc: 0.3900 - val_loss: 2.0015 - val_acc: 0.2300\n",
            "Epoch 480/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4824 - acc: 0.3957 - val_loss: 2.0102 - val_acc: 0.2367\n",
            "Epoch 481/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
            "Epoch 482/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0164 - val_acc: 0.2300\n",
            "Epoch 483/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0144 - val_acc: 0.2367\n",
            "Epoch 484/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0162 - val_acc: 0.2400\n",
            "Epoch 485/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4811 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2300\n",
            "Epoch 486/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0074 - val_acc: 0.2467\n",
            "Epoch 487/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0075 - val_acc: 0.2500\n",
            "Epoch 488/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0157 - val_acc: 0.2500\n",
            "Epoch 489/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2267\n",
            "Epoch 490/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0000 - val_acc: 0.2333\n",
            "Epoch 491/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4808 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
            "Epoch 492/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0007 - val_acc: 0.2267\n",
            "Epoch 493/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0076 - val_acc: 0.2333\n",
            "Epoch 494/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4802 - acc: 0.3900 - val_loss: 2.0072 - val_acc: 0.2233\n",
            "Epoch 495/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4792 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2333\n",
            "Epoch 496/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0112 - val_acc: 0.2433\n",
            "Epoch 497/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0122 - val_acc: 0.2467\n",
            "Epoch 498/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0468 - val_acc: 0.2367\n",
            "Epoch 499/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4775 - acc: 0.4014 - val_loss: 2.0281 - val_acc: 0.2367\n",
            "Epoch 500/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0262 - val_acc: 0.2367\n",
            "Epoch 501/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0258 - val_acc: 0.2300\n",
            "Epoch 502/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4760 - acc: 0.3943 - val_loss: 2.0261 - val_acc: 0.2267\n",
            "Epoch 503/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0202 - val_acc: 0.2267\n",
            "Epoch 504/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0240 - val_acc: 0.2267\n",
            "Epoch 505/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0196 - val_acc: 0.2400\n",
            "Epoch 506/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0154 - val_acc: 0.2300\n",
            "Epoch 507/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
            "Epoch 508/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0240 - val_acc: 0.2267\n",
            "Epoch 509/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0373 - val_acc: 0.2333\n",
            "Epoch 510/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
            "Epoch 511/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4737 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2267\n",
            "Epoch 512/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4739 - acc: 0.3971 - val_loss: 2.0106 - val_acc: 0.2467\n",
            "Epoch 513/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4732 - acc: 0.3986 - val_loss: 2.0137 - val_acc: 0.2433\n",
            "Epoch 514/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0268 - val_acc: 0.2267\n",
            "Epoch 515/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4734 - acc: 0.4014 - val_loss: 2.0250 - val_acc: 0.2300\n",
            "Epoch 516/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2267\n",
            "Epoch 517/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0338 - val_acc: 0.2500\n",
            "Epoch 518/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4740 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2267\n",
            "Epoch 519/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0238 - val_acc: 0.2300\n",
            "Epoch 520/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0307 - val_acc: 0.2400\n",
            "Epoch 521/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4713 - acc: 0.4129 - val_loss: 2.0126 - val_acc: 0.2333\n",
            "Epoch 522/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2267\n",
            "Epoch 523/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0293 - val_acc: 0.2267\n",
            "Epoch 524/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0230 - val_acc: 0.2333\n",
            "Epoch 525/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0285 - val_acc: 0.2467\n",
            "Epoch 526/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4711 - acc: 0.4029 - val_loss: 2.0247 - val_acc: 0.2267\n",
            "Epoch 527/1000\n",
            "700/700 [==============================] - 0s 406us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0259 - val_acc: 0.2300\n",
            "Epoch 528/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0291 - val_acc: 0.2267\n",
            "Epoch 529/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0337 - val_acc: 0.2267\n",
            "Epoch 530/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4686 - acc: 0.4000 - val_loss: 2.0412 - val_acc: 0.2267\n",
            "Epoch 531/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
            "Epoch 532/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
            "Epoch 533/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0311 - val_acc: 0.2300\n",
            "Epoch 534/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
            "Epoch 535/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0499 - val_acc: 0.2433\n",
            "Epoch 536/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0468 - val_acc: 0.2267\n",
            "Epoch 537/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0293 - val_acc: 0.2300\n",
            "Epoch 538/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4672 - acc: 0.3957 - val_loss: 2.0361 - val_acc: 0.2367\n",
            "Epoch 539/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0313 - val_acc: 0.2267\n",
            "Epoch 540/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2267\n",
            "Epoch 541/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0371 - val_acc: 0.2267\n",
            "Epoch 542/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4665 - acc: 0.4057 - val_loss: 2.0430 - val_acc: 0.2433\n",
            "Epoch 543/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0292 - val_acc: 0.2333\n",
            "Epoch 544/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0243 - val_acc: 0.2367\n",
            "Epoch 545/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0327 - val_acc: 0.2300\n",
            "Epoch 546/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4635 - acc: 0.4000 - val_loss: 2.0464 - val_acc: 0.2533\n",
            "Epoch 547/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.4657 - acc: 0.4000 - val_loss: 2.0517 - val_acc: 0.2400\n",
            "Epoch 548/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0295 - val_acc: 0.2300\n",
            "Epoch 549/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0262 - val_acc: 0.2333\n",
            "Epoch 550/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
            "Epoch 551/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4647 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2300\n",
            "Epoch 552/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0365 - val_acc: 0.2333\n",
            "Epoch 553/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
            "Epoch 554/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.4630 - acc: 0.3986 - val_loss: 2.0435 - val_acc: 0.2300\n",
            "Epoch 555/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0446 - val_acc: 0.2400\n",
            "Epoch 556/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0385 - val_acc: 0.2467\n",
            "Epoch 557/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2500\n",
            "Epoch 558/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4631 - acc: 0.4029 - val_loss: 2.0380 - val_acc: 0.2333\n",
            "Epoch 559/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0413 - val_acc: 0.2533\n",
            "Epoch 560/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0446 - val_acc: 0.2567\n",
            "Epoch 561/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0394 - val_acc: 0.2267\n",
            "Epoch 562/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4619 - acc: 0.4029 - val_loss: 2.0325 - val_acc: 0.2300\n",
            "Epoch 563/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
            "Epoch 564/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
            "Epoch 565/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0375 - val_acc: 0.2333\n",
            "Epoch 566/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0473 - val_acc: 0.2300\n",
            "Epoch 567/1000\n",
            "700/700 [==============================] - 0s 421us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0504 - val_acc: 0.2300\n",
            "Epoch 568/1000\n",
            "700/700 [==============================] - 0s 412us/step - loss: 1.4598 - acc: 0.4057 - val_loss: 2.0486 - val_acc: 0.2433\n",
            "Epoch 569/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4594 - acc: 0.4057 - val_loss: 2.0432 - val_acc: 0.2533\n",
            "Epoch 570/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4586 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
            "Epoch 571/1000\n",
            "700/700 [==============================] - 0s 416us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2300\n",
            "Epoch 572/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2333\n",
            "Epoch 573/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0551 - val_acc: 0.2533\n",
            "Epoch 574/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0408 - val_acc: 0.2500\n",
            "Epoch 575/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0449 - val_acc: 0.2267\n",
            "Epoch 576/1000\n",
            "700/700 [==============================] - 0s 447us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0468 - val_acc: 0.2300\n",
            "Epoch 577/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4583 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2300\n",
            "Epoch 578/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4577 - acc: 0.4071 - val_loss: 2.0453 - val_acc: 0.2367\n",
            "Epoch 579/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4584 - acc: 0.4057 - val_loss: 2.0428 - val_acc: 0.2267\n",
            "Epoch 580/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4574 - acc: 0.4086 - val_loss: 2.0531 - val_acc: 0.2367\n",
            "Epoch 581/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4570 - acc: 0.4071 - val_loss: 2.0488 - val_acc: 0.2567\n",
            "Epoch 582/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0513 - val_acc: 0.2267\n",
            "Epoch 583/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0529 - val_acc: 0.2267\n",
            "Epoch 584/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2267\n",
            "Epoch 585/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0556 - val_acc: 0.2300\n",
            "Epoch 586/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4549 - acc: 0.4043 - val_loss: 2.0555 - val_acc: 0.2500\n",
            "Epoch 587/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2333\n",
            "Epoch 588/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4560 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2300\n",
            "Epoch 589/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4553 - acc: 0.4057 - val_loss: 2.0576 - val_acc: 0.2267\n",
            "Epoch 590/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
            "Epoch 591/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0605 - val_acc: 0.2267\n",
            "Epoch 592/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4544 - acc: 0.4086 - val_loss: 2.0557 - val_acc: 0.2333\n",
            "Epoch 593/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0498 - val_acc: 0.2267\n",
            "Epoch 594/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4540 - acc: 0.4129 - val_loss: 2.0513 - val_acc: 0.2333\n",
            "Epoch 595/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4543 - acc: 0.4057 - val_loss: 2.0569 - val_acc: 0.2433\n",
            "Epoch 596/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0472 - val_acc: 0.2300\n",
            "Epoch 597/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0491 - val_acc: 0.2500\n",
            "Epoch 598/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4537 - acc: 0.3986 - val_loss: 2.0563 - val_acc: 0.2267\n",
            "Epoch 599/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0478 - val_acc: 0.2333\n",
            "Epoch 600/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0625 - val_acc: 0.2300\n",
            "Epoch 601/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0623 - val_acc: 0.2433\n",
            "Epoch 602/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4526 - acc: 0.4029 - val_loss: 2.0585 - val_acc: 0.2333\n",
            "Epoch 603/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0504 - val_acc: 0.2400\n",
            "Epoch 604/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4525 - acc: 0.4029 - val_loss: 2.0489 - val_acc: 0.2433\n",
            "Epoch 605/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0553 - val_acc: 0.2367\n",
            "Epoch 606/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
            "Epoch 607/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4518 - acc: 0.4100 - val_loss: 2.0580 - val_acc: 0.2300\n",
            "Epoch 608/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2367\n",
            "Epoch 609/1000\n",
            "700/700 [==============================] - 0s 447us/step - loss: 1.4500 - acc: 0.4157 - val_loss: 2.0635 - val_acc: 0.2567\n",
            "Epoch 610/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
            "Epoch 611/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0608 - val_acc: 0.2367\n",
            "Epoch 612/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
            "Epoch 613/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4505 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2300\n",
            "Epoch 614/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0686 - val_acc: 0.2500\n",
            "Epoch 615/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4502 - acc: 0.4129 - val_loss: 2.0535 - val_acc: 0.2533\n",
            "Epoch 616/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4495 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2333\n",
            "Epoch 617/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0653 - val_acc: 0.2533\n",
            "Epoch 618/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0597 - val_acc: 0.2400\n",
            "Epoch 619/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0671 - val_acc: 0.2333\n",
            "Epoch 620/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4488 - acc: 0.4171 - val_loss: 2.0564 - val_acc: 0.2300\n",
            "Epoch 621/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4487 - acc: 0.4129 - val_loss: 2.0741 - val_acc: 0.2333\n",
            "Epoch 622/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0741 - val_acc: 0.2367\n",
            "Epoch 623/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0690 - val_acc: 0.2267\n",
            "Epoch 624/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0689 - val_acc: 0.2367\n",
            "Epoch 625/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4479 - acc: 0.4029 - val_loss: 2.0724 - val_acc: 0.2367\n",
            "Epoch 626/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0535 - val_acc: 0.2367\n",
            "Epoch 627/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0632 - val_acc: 0.2333\n",
            "Epoch 628/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.4459 - acc: 0.4157 - val_loss: 2.0503 - val_acc: 0.2400\n",
            "Epoch 629/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0615 - val_acc: 0.2333\n",
            "Epoch 630/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.4460 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2333\n",
            "Epoch 631/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0818 - val_acc: 0.2400\n",
            "Epoch 632/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2400\n",
            "Epoch 633/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0829 - val_acc: 0.2367\n",
            "Epoch 634/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0715 - val_acc: 0.2333\n",
            "Epoch 635/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0653 - val_acc: 0.2567\n",
            "Epoch 636/1000\n",
            "700/700 [==============================] - 0s 471us/step - loss: 1.4463 - acc: 0.4129 - val_loss: 2.0669 - val_acc: 0.2333\n",
            "Epoch 637/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0764 - val_acc: 0.2367\n",
            "Epoch 638/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0816 - val_acc: 0.2300\n",
            "Epoch 639/1000\n",
            "700/700 [==============================] - 0s 584us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
            "Epoch 640/1000\n",
            "700/700 [==============================] - 0s 568us/step - loss: 1.4441 - acc: 0.4157 - val_loss: 2.0581 - val_acc: 0.2367\n",
            "Epoch 641/1000\n",
            "700/700 [==============================] - 0s 552us/step - loss: 1.4437 - acc: 0.4143 - val_loss: 2.0742 - val_acc: 0.2467\n",
            "Epoch 642/1000\n",
            "700/700 [==============================] - 0s 573us/step - loss: 1.4448 - acc: 0.4100 - val_loss: 2.0819 - val_acc: 0.2433\n",
            "Epoch 643/1000\n",
            "700/700 [==============================] - 0s 572us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0856 - val_acc: 0.2300\n",
            "Epoch 644/1000\n",
            "700/700 [==============================] - 0s 563us/step - loss: 1.4440 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2367\n",
            "Epoch 645/1000\n",
            "700/700 [==============================] - 0s 566us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0797 - val_acc: 0.2333\n",
            "Epoch 646/1000\n",
            "700/700 [==============================] - 0s 564us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
            "Epoch 647/1000\n",
            "700/700 [==============================] - 0s 570us/step - loss: 1.4423 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2367\n",
            "Epoch 648/1000\n",
            "700/700 [==============================] - 0s 559us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0860 - val_acc: 0.2333\n",
            "Epoch 649/1000\n",
            "700/700 [==============================] - 0s 560us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0823 - val_acc: 0.2333\n",
            "Epoch 650/1000\n",
            "700/700 [==============================] - 0s 592us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0725 - val_acc: 0.2333\n",
            "Epoch 651/1000\n",
            "700/700 [==============================] - 0s 547us/step - loss: 1.4418 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
            "Epoch 652/1000\n",
            "700/700 [==============================] - 0s 571us/step - loss: 1.4430 - acc: 0.4114 - val_loss: 2.0737 - val_acc: 0.2333\n",
            "Epoch 653/1000\n",
            "700/700 [==============================] - 0s 563us/step - loss: 1.4415 - acc: 0.4171 - val_loss: 2.0781 - val_acc: 0.2433\n",
            "Epoch 654/1000\n",
            "700/700 [==============================] - 0s 534us/step - loss: 1.4414 - acc: 0.4143 - val_loss: 2.0641 - val_acc: 0.2467\n",
            "Epoch 655/1000\n",
            "700/700 [==============================] - 0s 575us/step - loss: 1.4406 - acc: 0.4100 - val_loss: 2.0746 - val_acc: 0.2533\n",
            "Epoch 656/1000\n",
            "700/700 [==============================] - 0s 561us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0850 - val_acc: 0.2433\n",
            "Epoch 657/1000\n",
            "700/700 [==============================] - 0s 523us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0809 - val_acc: 0.2300\n",
            "Epoch 658/1000\n",
            "700/700 [==============================] - 0s 594us/step - loss: 1.4409 - acc: 0.4143 - val_loss: 2.0781 - val_acc: 0.2367\n",
            "Epoch 659/1000\n",
            "700/700 [==============================] - 0s 580us/step - loss: 1.4404 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2467\n",
            "Epoch 660/1000\n",
            "700/700 [==============================] - 0s 567us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0796 - val_acc: 0.2367\n",
            "Epoch 661/1000\n",
            "700/700 [==============================] - 0s 566us/step - loss: 1.4418 - acc: 0.4086 - val_loss: 2.0753 - val_acc: 0.2367\n",
            "Epoch 662/1000\n",
            "700/700 [==============================] - 0s 564us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0794 - val_acc: 0.2367\n",
            "Epoch 663/1000\n",
            "700/700 [==============================] - 0s 549us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0953 - val_acc: 0.2400\n",
            "Epoch 664/1000\n",
            "700/700 [==============================] - 0s 558us/step - loss: 1.4394 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
            "Epoch 665/1000\n",
            "700/700 [==============================] - 0s 583us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.0887 - val_acc: 0.2333\n",
            "Epoch 666/1000\n",
            "700/700 [==============================] - 0s 520us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0808 - val_acc: 0.2533\n",
            "Epoch 667/1000\n",
            "700/700 [==============================] - 0s 573us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0751 - val_acc: 0.2367\n",
            "Epoch 668/1000\n",
            "700/700 [==============================] - 0s 606us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0902 - val_acc: 0.2567\n",
            "Epoch 669/1000\n",
            "700/700 [==============================] - 0s 531us/step - loss: 1.4382 - acc: 0.4157 - val_loss: 2.0931 - val_acc: 0.2333\n",
            "Epoch 670/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.0815 - val_acc: 0.2333\n",
            "Epoch 671/1000\n",
            "700/700 [==============================] - 0s 499us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0801 - val_acc: 0.2533\n",
            "Epoch 672/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4382 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2367\n",
            "Epoch 673/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4384 - acc: 0.4186 - val_loss: 2.0821 - val_acc: 0.2400\n",
            "Epoch 674/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4374 - acc: 0.4086 - val_loss: 2.1027 - val_acc: 0.2433\n",
            "Epoch 675/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
            "Epoch 676/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2567\n",
            "Epoch 677/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0972 - val_acc: 0.2300\n",
            "Epoch 678/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4355 - acc: 0.4200 - val_loss: 2.0724 - val_acc: 0.2333\n",
            "Epoch 679/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0890 - val_acc: 0.2367\n",
            "Epoch 680/1000\n",
            "700/700 [==============================] - 0s 474us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
            "Epoch 681/1000\n",
            "700/700 [==============================] - 0s 496us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0805 - val_acc: 0.2400\n",
            "Epoch 682/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0854 - val_acc: 0.2567\n",
            "Epoch 683/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0779 - val_acc: 0.2500\n",
            "Epoch 684/1000\n",
            "700/700 [==============================] - 0s 487us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0887 - val_acc: 0.2600\n",
            "Epoch 685/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4356 - acc: 0.4143 - val_loss: 2.0846 - val_acc: 0.2567\n",
            "Epoch 686/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4352 - acc: 0.4200 - val_loss: 2.1067 - val_acc: 0.2533\n",
            "Epoch 687/1000\n",
            "700/700 [==============================] - 0s 494us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0772 - val_acc: 0.2367\n",
            "Epoch 688/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0829 - val_acc: 0.2400\n",
            "Epoch 689/1000\n",
            "700/700 [==============================] - 0s 484us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0925 - val_acc: 0.2367\n",
            "Epoch 690/1000\n",
            "700/700 [==============================] - 0s 495us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.0995 - val_acc: 0.2333\n",
            "Epoch 691/1000\n",
            "700/700 [==============================] - 0s 482us/step - loss: 1.4337 - acc: 0.4229 - val_loss: 2.0944 - val_acc: 0.2333\n",
            "Epoch 692/1000\n",
            "700/700 [==============================] - 0s 483us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
            "Epoch 693/1000\n",
            "700/700 [==============================] - 0s 501us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
            "Epoch 694/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4335 - acc: 0.4186 - val_loss: 2.1067 - val_acc: 0.2467\n",
            "Epoch 695/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.4348 - acc: 0.4171 - val_loss: 2.0871 - val_acc: 0.2567\n",
            "Epoch 696/1000\n",
            "700/700 [==============================] - 0s 484us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0991 - val_acc: 0.2333\n",
            "Epoch 697/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4337 - acc: 0.4186 - val_loss: 2.1061 - val_acc: 0.2467\n",
            "Epoch 698/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4333 - acc: 0.4257 - val_loss: 2.0948 - val_acc: 0.2433\n",
            "Epoch 699/1000\n",
            "700/700 [==============================] - 0s 491us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.0957 - val_acc: 0.2400\n",
            "Epoch 700/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0952 - val_acc: 0.2467\n",
            "Epoch 701/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.4316 - acc: 0.4171 - val_loss: 2.0921 - val_acc: 0.2433\n",
            "Epoch 702/1000\n",
            "700/700 [==============================] - 0s 490us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0981 - val_acc: 0.2367\n",
            "Epoch 703/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1061 - val_acc: 0.2333\n",
            "Epoch 704/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4325 - acc: 0.4214 - val_loss: 2.0935 - val_acc: 0.2433\n",
            "Epoch 705/1000\n",
            "700/700 [==============================] - 0s 516us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0879 - val_acc: 0.2400\n",
            "Epoch 706/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0806 - val_acc: 0.2400\n",
            "Epoch 707/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.0931 - val_acc: 0.2367\n",
            "Epoch 708/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4316 - acc: 0.4214 - val_loss: 2.0923 - val_acc: 0.2333\n",
            "Epoch 709/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4296 - acc: 0.4186 - val_loss: 2.1160 - val_acc: 0.2533\n",
            "Epoch 710/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4314 - acc: 0.4229 - val_loss: 2.0957 - val_acc: 0.2467\n",
            "Epoch 711/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.4304 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2367\n",
            "Epoch 712/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4300 - acc: 0.4214 - val_loss: 2.1035 - val_acc: 0.2567\n",
            "Epoch 713/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.4310 - acc: 0.4186 - val_loss: 2.0861 - val_acc: 0.2400\n",
            "Epoch 714/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4305 - acc: 0.4243 - val_loss: 2.0996 - val_acc: 0.2367\n",
            "Epoch 715/1000\n",
            "700/700 [==============================] - 0s 483us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.0936 - val_acc: 0.2600\n",
            "Epoch 716/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.4305 - acc: 0.4157 - val_loss: 2.1060 - val_acc: 0.2367\n",
            "Epoch 717/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1014 - val_acc: 0.2367\n",
            "Epoch 718/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4289 - acc: 0.4186 - val_loss: 2.1246 - val_acc: 0.2533\n",
            "Epoch 719/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4303 - acc: 0.4186 - val_loss: 2.1100 - val_acc: 0.2400\n",
            "Epoch 720/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4295 - acc: 0.4214 - val_loss: 2.1052 - val_acc: 0.2367\n",
            "Epoch 721/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1038 - val_acc: 0.2433\n",
            "Epoch 722/1000\n",
            "700/700 [==============================] - 0s 447us/step - loss: 1.4286 - acc: 0.4200 - val_loss: 2.1045 - val_acc: 0.2367\n",
            "Epoch 723/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4282 - acc: 0.4214 - val_loss: 2.0911 - val_acc: 0.2400\n",
            "Epoch 724/1000\n",
            "700/700 [==============================] - 0s 477us/step - loss: 1.4281 - acc: 0.4257 - val_loss: 2.1101 - val_acc: 0.2367\n",
            "Epoch 725/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4277 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2433\n",
            "Epoch 726/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4278 - acc: 0.4257 - val_loss: 2.0962 - val_acc: 0.2367\n",
            "Epoch 727/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4273 - acc: 0.4214 - val_loss: 2.1264 - val_acc: 0.2333\n",
            "Epoch 728/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4276 - acc: 0.4200 - val_loss: 2.0961 - val_acc: 0.2400\n",
            "Epoch 729/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4269 - acc: 0.4229 - val_loss: 2.1197 - val_acc: 0.2467\n",
            "Epoch 730/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1247 - val_acc: 0.2400\n",
            "Epoch 731/1000\n",
            "700/700 [==============================] - 0s 482us/step - loss: 1.4277 - acc: 0.4143 - val_loss: 2.1096 - val_acc: 0.2367\n",
            "Epoch 732/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1076 - val_acc: 0.2400\n",
            "Epoch 733/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.4263 - acc: 0.4286 - val_loss: 2.1008 - val_acc: 0.2400\n",
            "Epoch 734/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.4271 - acc: 0.4214 - val_loss: 2.1178 - val_acc: 0.2400\n",
            "Epoch 735/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4261 - acc: 0.4286 - val_loss: 2.1092 - val_acc: 0.2367\n",
            "Epoch 736/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4249 - acc: 0.4300 - val_loss: 2.1022 - val_acc: 0.2400\n",
            "Epoch 737/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4265 - acc: 0.4229 - val_loss: 2.1194 - val_acc: 0.2433\n",
            "Epoch 738/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4265 - acc: 0.4200 - val_loss: 2.1078 - val_acc: 0.2467\n",
            "Epoch 739/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1167 - val_acc: 0.2367\n",
            "Epoch 740/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.4250 - acc: 0.4314 - val_loss: 2.1048 - val_acc: 0.2400\n",
            "Epoch 741/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1189 - val_acc: 0.2567\n",
            "Epoch 742/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4252 - acc: 0.4143 - val_loss: 2.1010 - val_acc: 0.2533\n",
            "Epoch 743/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1042 - val_acc: 0.2533\n",
            "Epoch 744/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1045 - val_acc: 0.2433\n",
            "Epoch 745/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1158 - val_acc: 0.2533\n",
            "Epoch 746/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1062 - val_acc: 0.2400\n",
            "Epoch 747/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.4251 - acc: 0.4157 - val_loss: 2.1123 - val_acc: 0.2433\n",
            "Epoch 748/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1289 - val_acc: 0.2600\n",
            "Epoch 749/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0960 - val_acc: 0.2333\n",
            "Epoch 750/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.4239 - acc: 0.4329 - val_loss: 2.1004 - val_acc: 0.2300\n",
            "Epoch 751/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4224 - acc: 0.4171 - val_loss: 2.1130 - val_acc: 0.2400\n",
            "Epoch 752/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4233 - acc: 0.4243 - val_loss: 2.1173 - val_acc: 0.2367\n",
            "Epoch 753/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.1337 - val_acc: 0.2333\n",
            "Epoch 754/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4235 - acc: 0.4271 - val_loss: 2.1186 - val_acc: 0.2333\n",
            "Epoch 755/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1169 - val_acc: 0.2467\n",
            "Epoch 756/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1151 - val_acc: 0.2400\n",
            "Epoch 757/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4233 - acc: 0.4200 - val_loss: 2.1210 - val_acc: 0.2433\n",
            "Epoch 758/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4220 - acc: 0.4300 - val_loss: 2.1190 - val_acc: 0.2433\n",
            "Epoch 759/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4221 - acc: 0.4271 - val_loss: 2.1112 - val_acc: 0.2400\n",
            "Epoch 760/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4218 - acc: 0.4329 - val_loss: 2.1117 - val_acc: 0.2400\n",
            "Epoch 761/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4215 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2500\n",
            "Epoch 762/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4225 - acc: 0.4257 - val_loss: 2.1261 - val_acc: 0.2400\n",
            "Epoch 763/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.4215 - acc: 0.4200 - val_loss: 2.1152 - val_acc: 0.2400\n",
            "Epoch 764/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4227 - acc: 0.4300 - val_loss: 2.1314 - val_acc: 0.2433\n",
            "Epoch 765/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4203 - acc: 0.4214 - val_loss: 2.1405 - val_acc: 0.2333\n",
            "Epoch 766/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4217 - acc: 0.4214 - val_loss: 2.1154 - val_acc: 0.2400\n",
            "Epoch 767/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1160 - val_acc: 0.2367\n",
            "Epoch 768/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1068 - val_acc: 0.2400\n",
            "Epoch 769/1000\n",
            "700/700 [==============================] - 0s 410us/step - loss: 1.4207 - acc: 0.4243 - val_loss: 2.1165 - val_acc: 0.2367\n",
            "Epoch 770/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4200 - acc: 0.4214 - val_loss: 2.1088 - val_acc: 0.2333\n",
            "Epoch 771/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1229 - val_acc: 0.2367\n",
            "Epoch 772/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4202 - acc: 0.4229 - val_loss: 2.1255 - val_acc: 0.2433\n",
            "Epoch 773/1000\n",
            "700/700 [==============================] - 0s 486us/step - loss: 1.4200 - acc: 0.4229 - val_loss: 2.1326 - val_acc: 0.2500\n",
            "Epoch 774/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1295 - val_acc: 0.2400\n",
            "Epoch 775/1000\n",
            "700/700 [==============================] - 0s 443us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1295 - val_acc: 0.2533\n",
            "Epoch 776/1000\n",
            "700/700 [==============================] - 0s 475us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
            "Epoch 777/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4177 - acc: 0.4314 - val_loss: 2.1345 - val_acc: 0.2333\n",
            "Epoch 778/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.4190 - acc: 0.4214 - val_loss: 2.1203 - val_acc: 0.2333\n",
            "Epoch 779/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4191 - acc: 0.4300 - val_loss: 2.1231 - val_acc: 0.2333\n",
            "Epoch 780/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4190 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2400\n",
            "Epoch 781/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1239 - val_acc: 0.2467\n",
            "Epoch 782/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4184 - acc: 0.4257 - val_loss: 2.1057 - val_acc: 0.2400\n",
            "Epoch 783/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1295 - val_acc: 0.2433\n",
            "Epoch 784/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4181 - acc: 0.4300 - val_loss: 2.1362 - val_acc: 0.2400\n",
            "Epoch 785/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1419 - val_acc: 0.2367\n",
            "Epoch 786/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4180 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
            "Epoch 787/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1135 - val_acc: 0.2500\n",
            "Epoch 788/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2400\n",
            "Epoch 789/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1256 - val_acc: 0.2400\n",
            "Epoch 790/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1284 - val_acc: 0.2400\n",
            "Epoch 791/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2500\n",
            "Epoch 792/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.4171 - acc: 0.4229 - val_loss: 2.1204 - val_acc: 0.2367\n",
            "Epoch 793/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4166 - acc: 0.4257 - val_loss: 2.1365 - val_acc: 0.2500\n",
            "Epoch 794/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4169 - acc: 0.4271 - val_loss: 2.1308 - val_acc: 0.2367\n",
            "Epoch 795/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4164 - acc: 0.4314 - val_loss: 2.1278 - val_acc: 0.2400\n",
            "Epoch 796/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4160 - acc: 0.4300 - val_loss: 2.1290 - val_acc: 0.2367\n",
            "Epoch 797/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1355 - val_acc: 0.2367\n",
            "Epoch 798/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4162 - acc: 0.4386 - val_loss: 2.1362 - val_acc: 0.2400\n",
            "Epoch 799/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1291 - val_acc: 0.2567\n",
            "Epoch 800/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.4159 - acc: 0.4200 - val_loss: 2.1378 - val_acc: 0.2333\n",
            "Epoch 801/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.2333\n",
            "Epoch 802/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1718 - val_acc: 0.2400\n",
            "Epoch 803/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1338 - val_acc: 0.2600\n",
            "Epoch 804/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1272 - val_acc: 0.2433\n",
            "Epoch 805/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1285 - val_acc: 0.2467\n",
            "Epoch 806/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4148 - acc: 0.4357 - val_loss: 2.1285 - val_acc: 0.2400\n",
            "Epoch 807/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4148 - acc: 0.4386 - val_loss: 2.1343 - val_acc: 0.2500\n",
            "Epoch 808/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4143 - acc: 0.4314 - val_loss: 2.1340 - val_acc: 0.2400\n",
            "Epoch 809/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2467\n",
            "Epoch 810/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4139 - acc: 0.4357 - val_loss: 2.1360 - val_acc: 0.2367\n",
            "Epoch 811/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1368 - val_acc: 0.2400\n",
            "Epoch 812/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4141 - acc: 0.4271 - val_loss: 2.1261 - val_acc: 0.2400\n",
            "Epoch 813/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1430 - val_acc: 0.2400\n",
            "Epoch 814/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4131 - acc: 0.4286 - val_loss: 2.1356 - val_acc: 0.2533\n",
            "Epoch 815/1000\n",
            "700/700 [==============================] - 0s 470us/step - loss: 1.4139 - acc: 0.4314 - val_loss: 2.1410 - val_acc: 0.2467\n",
            "Epoch 816/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4136 - acc: 0.4300 - val_loss: 2.1348 - val_acc: 0.2367\n",
            "Epoch 817/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4116 - acc: 0.4300 - val_loss: 2.1359 - val_acc: 0.2367\n",
            "Epoch 818/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1431 - val_acc: 0.2367\n",
            "Epoch 819/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4110 - acc: 0.4357 - val_loss: 2.1535 - val_acc: 0.2600\n",
            "Epoch 820/1000\n",
            "700/700 [==============================] - 0s 417us/step - loss: 1.4131 - acc: 0.4329 - val_loss: 2.1379 - val_acc: 0.2567\n",
            "Epoch 821/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1497 - val_acc: 0.2467\n",
            "Epoch 822/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1381 - val_acc: 0.2367\n",
            "Epoch 823/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4114 - acc: 0.4271 - val_loss: 2.1430 - val_acc: 0.2433\n",
            "Epoch 824/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.4110 - acc: 0.4300 - val_loss: 2.1438 - val_acc: 0.2433\n",
            "Epoch 825/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1583 - val_acc: 0.2467\n",
            "Epoch 826/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4122 - acc: 0.4271 - val_loss: 2.1483 - val_acc: 0.2467\n",
            "Epoch 827/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1481 - val_acc: 0.2400\n",
            "Epoch 828/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4118 - acc: 0.4343 - val_loss: 2.1369 - val_acc: 0.2367\n",
            "Epoch 829/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1411 - val_acc: 0.2433\n",
            "Epoch 830/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1457 - val_acc: 0.2400\n",
            "Epoch 831/1000\n",
            "700/700 [==============================] - 0s 475us/step - loss: 1.4105 - acc: 0.4443 - val_loss: 2.1591 - val_acc: 0.2467\n",
            "Epoch 832/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.4111 - acc: 0.4343 - val_loss: 2.1598 - val_acc: 0.2500\n",
            "Epoch 833/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4110 - acc: 0.4243 - val_loss: 2.1645 - val_acc: 0.2467\n",
            "Epoch 834/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1743 - val_acc: 0.2433\n",
            "Epoch 835/1000\n",
            "700/700 [==============================] - 0s 442us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2367\n",
            "Epoch 836/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1518 - val_acc: 0.2500\n",
            "Epoch 837/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1380 - val_acc: 0.2433\n",
            "Epoch 838/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1500 - val_acc: 0.2367\n",
            "Epoch 839/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1492 - val_acc: 0.2367\n",
            "Epoch 840/1000\n",
            "700/700 [==============================] - 0s 433us/step - loss: 1.4081 - acc: 0.4343 - val_loss: 2.1386 - val_acc: 0.2433\n",
            "Epoch 841/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4092 - acc: 0.4371 - val_loss: 2.1470 - val_acc: 0.2367\n",
            "Epoch 842/1000\n",
            "700/700 [==============================] - 0s 455us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1594 - val_acc: 0.2500\n",
            "Epoch 843/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.4090 - acc: 0.4314 - val_loss: 2.1468 - val_acc: 0.2367\n",
            "Epoch 844/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4082 - acc: 0.4300 - val_loss: 2.1617 - val_acc: 0.2367\n",
            "Epoch 845/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.4088 - acc: 0.4314 - val_loss: 2.1402 - val_acc: 0.2367\n",
            "Epoch 846/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1484 - val_acc: 0.2400\n",
            "Epoch 847/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1584 - val_acc: 0.2433\n",
            "Epoch 848/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.4079 - acc: 0.4371 - val_loss: 2.1529 - val_acc: 0.2533\n",
            "Epoch 849/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4086 - acc: 0.4300 - val_loss: 2.1555 - val_acc: 0.2433\n",
            "Epoch 850/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1484 - val_acc: 0.2367\n",
            "Epoch 851/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4071 - acc: 0.4229 - val_loss: 2.1482 - val_acc: 0.2333\n",
            "Epoch 852/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.4086 - acc: 0.4371 - val_loss: 2.1509 - val_acc: 0.2433\n",
            "Epoch 853/1000\n",
            "700/700 [==============================] - 0s 414us/step - loss: 1.4066 - acc: 0.4329 - val_loss: 2.1501 - val_acc: 0.2367\n",
            "Epoch 854/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4046 - acc: 0.4371 - val_loss: 2.1745 - val_acc: 0.2600\n",
            "Epoch 855/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1510 - val_acc: 0.2333\n",
            "Epoch 856/1000\n",
            "700/700 [==============================] - 0s 436us/step - loss: 1.4074 - acc: 0.4357 - val_loss: 2.1598 - val_acc: 0.2500\n",
            "Epoch 857/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4067 - acc: 0.4286 - val_loss: 2.1580 - val_acc: 0.2467\n",
            "Epoch 858/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.4066 - acc: 0.4343 - val_loss: 2.1567 - val_acc: 0.2367\n",
            "Epoch 859/1000\n",
            "700/700 [==============================] - 0s 429us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1554 - val_acc: 0.2367\n",
            "Epoch 860/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4057 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2533\n",
            "Epoch 861/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4064 - acc: 0.4343 - val_loss: 2.1655 - val_acc: 0.2433\n",
            "Epoch 862/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4071 - acc: 0.4271 - val_loss: 2.1672 - val_acc: 0.2533\n",
            "Epoch 863/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4055 - acc: 0.4329 - val_loss: 2.1677 - val_acc: 0.2500\n",
            "Epoch 864/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1628 - val_acc: 0.2533\n",
            "Epoch 865/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1682 - val_acc: 0.2633\n",
            "Epoch 866/1000\n",
            "700/700 [==============================] - 0s 420us/step - loss: 1.4049 - acc: 0.4314 - val_loss: 2.1387 - val_acc: 0.2433\n",
            "Epoch 867/1000\n",
            "700/700 [==============================] - 0s 441us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1681 - val_acc: 0.2433\n",
            "Epoch 868/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.4054 - acc: 0.4357 - val_loss: 2.1608 - val_acc: 0.2467\n",
            "Epoch 869/1000\n",
            "700/700 [==============================] - 0s 427us/step - loss: 1.4050 - acc: 0.4386 - val_loss: 2.1594 - val_acc: 0.2400\n",
            "Epoch 870/1000\n",
            "700/700 [==============================] - 0s 430us/step - loss: 1.4034 - acc: 0.4357 - val_loss: 2.1720 - val_acc: 0.2467\n",
            "Epoch 871/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1759 - val_acc: 0.2467\n",
            "Epoch 872/1000\n",
            "700/700 [==============================] - 0s 411us/step - loss: 1.4037 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2567\n",
            "Epoch 873/1000\n",
            "700/700 [==============================] - 0s 425us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1424 - val_acc: 0.2367\n",
            "Epoch 874/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2367\n",
            "Epoch 875/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4038 - acc: 0.4329 - val_loss: 2.1739 - val_acc: 0.2467\n",
            "Epoch 876/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.4035 - acc: 0.4314 - val_loss: 2.1520 - val_acc: 0.2433\n",
            "Epoch 877/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4037 - acc: 0.4271 - val_loss: 2.1733 - val_acc: 0.2367\n",
            "Epoch 878/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2400\n",
            "Epoch 879/1000\n",
            "700/700 [==============================] - 0s 423us/step - loss: 1.4012 - acc: 0.4371 - val_loss: 2.1696 - val_acc: 0.2400\n",
            "Epoch 880/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.4051 - acc: 0.4329 - val_loss: 2.1589 - val_acc: 0.2400\n",
            "Epoch 881/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.4035 - acc: 0.4429 - val_loss: 2.1855 - val_acc: 0.2500\n",
            "Epoch 882/1000\n",
            "700/700 [==============================] - 0s 446us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1721 - val_acc: 0.2400\n",
            "Epoch 883/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4044 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2400\n",
            "Epoch 884/1000\n",
            "700/700 [==============================] - 0s 480us/step - loss: 1.4027 - acc: 0.4314 - val_loss: 2.1799 - val_acc: 0.2533\n",
            "Epoch 885/1000\n",
            "700/700 [==============================] - 0s 454us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1444 - val_acc: 0.2433\n",
            "Epoch 886/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4036 - acc: 0.4386 - val_loss: 2.1664 - val_acc: 0.2467\n",
            "Epoch 887/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.4026 - acc: 0.4371 - val_loss: 2.1546 - val_acc: 0.2367\n",
            "Epoch 888/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1653 - val_acc: 0.2400\n",
            "Epoch 889/1000\n",
            "700/700 [==============================] - 0s 456us/step - loss: 1.4010 - acc: 0.4443 - val_loss: 2.1763 - val_acc: 0.2600\n",
            "Epoch 890/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.4028 - acc: 0.4386 - val_loss: 2.1675 - val_acc: 0.2567\n",
            "Epoch 891/1000\n",
            "700/700 [==============================] - 0s 435us/step - loss: 1.4024 - acc: 0.4271 - val_loss: 2.1707 - val_acc: 0.2433\n",
            "Epoch 892/1000\n",
            "700/700 [==============================] - 0s 448us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1736 - val_acc: 0.2433\n",
            "Epoch 893/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4018 - acc: 0.4357 - val_loss: 2.1794 - val_acc: 0.2433\n",
            "Epoch 894/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.4020 - acc: 0.4429 - val_loss: 2.1670 - val_acc: 0.2400\n",
            "Epoch 895/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.4012 - acc: 0.4343 - val_loss: 2.1696 - val_acc: 0.2467\n",
            "Epoch 896/1000\n",
            "700/700 [==============================] - 0s 495us/step - loss: 1.4014 - acc: 0.4357 - val_loss: 2.1745 - val_acc: 0.2600\n",
            "Epoch 897/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.4017 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2533\n",
            "Epoch 898/1000\n",
            "700/700 [==============================] - 0s 407us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1869 - val_acc: 0.2467\n",
            "Epoch 899/1000\n",
            "700/700 [==============================] - 0s 419us/step - loss: 1.4015 - acc: 0.4343 - val_loss: 2.1634 - val_acc: 0.2467\n",
            "Epoch 900/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1660 - val_acc: 0.2467\n",
            "Epoch 901/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1780 - val_acc: 0.2533\n",
            "Epoch 902/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.4001 - acc: 0.4343 - val_loss: 2.1718 - val_acc: 0.2467\n",
            "Epoch 903/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.3992 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2633\n",
            "Epoch 904/1000\n",
            "700/700 [==============================] - 0s 434us/step - loss: 1.3991 - acc: 0.4357 - val_loss: 2.1637 - val_acc: 0.2400\n",
            "Epoch 905/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.4010 - acc: 0.4400 - val_loss: 2.1595 - val_acc: 0.2400\n",
            "Epoch 906/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.3998 - acc: 0.4371 - val_loss: 2.1560 - val_acc: 0.2367\n",
            "Epoch 907/1000\n",
            "700/700 [==============================] - 0s 477us/step - loss: 1.4003 - acc: 0.4386 - val_loss: 2.1815 - val_acc: 0.2467\n",
            "Epoch 908/1000\n",
            "700/700 [==============================] - 0s 465us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1730 - val_acc: 0.2433\n",
            "Epoch 909/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.3993 - acc: 0.4329 - val_loss: 2.1789 - val_acc: 0.2500\n",
            "Epoch 910/1000\n",
            "700/700 [==============================] - 0s 464us/step - loss: 1.4004 - acc: 0.4357 - val_loss: 2.1613 - val_acc: 0.2400\n",
            "Epoch 911/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.3991 - acc: 0.4371 - val_loss: 2.1790 - val_acc: 0.2367\n",
            "Epoch 912/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.3995 - acc: 0.4400 - val_loss: 2.1687 - val_acc: 0.2367\n",
            "Epoch 913/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.4000 - acc: 0.4371 - val_loss: 2.1881 - val_acc: 0.2433\n",
            "Epoch 914/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1862 - val_acc: 0.2567\n",
            "Epoch 915/1000\n",
            "700/700 [==============================] - 0s 432us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2467\n",
            "Epoch 916/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.3987 - acc: 0.4386 - val_loss: 2.1795 - val_acc: 0.2400\n",
            "Epoch 917/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.3978 - acc: 0.4400 - val_loss: 2.1797 - val_acc: 0.2400\n",
            "Epoch 918/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.3970 - acc: 0.4386 - val_loss: 2.1789 - val_acc: 0.2533\n",
            "Epoch 919/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.3984 - acc: 0.4329 - val_loss: 2.1871 - val_acc: 0.2433\n",
            "Epoch 920/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1695 - val_acc: 0.2500\n",
            "Epoch 921/1000\n",
            "700/700 [==============================] - 0s 462us/step - loss: 1.3984 - acc: 0.4357 - val_loss: 2.1721 - val_acc: 0.2400\n",
            "Epoch 922/1000\n",
            "700/700 [==============================] - 0s 480us/step - loss: 1.3967 - acc: 0.4400 - val_loss: 2.1838 - val_acc: 0.2500\n",
            "Epoch 923/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1709 - val_acc: 0.2567\n",
            "Epoch 924/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1766 - val_acc: 0.2467\n",
            "Epoch 925/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1822 - val_acc: 0.2367\n",
            "Epoch 926/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.3972 - acc: 0.4443 - val_loss: 2.1771 - val_acc: 0.2467\n",
            "Epoch 927/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1778 - val_acc: 0.2400\n",
            "Epoch 928/1000\n",
            "700/700 [==============================] - 0s 444us/step - loss: 1.3971 - acc: 0.4400 - val_loss: 2.1921 - val_acc: 0.2433\n",
            "Epoch 929/1000\n",
            "700/700 [==============================] - 0s 459us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1917 - val_acc: 0.2400\n",
            "Epoch 930/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 1.3971 - acc: 0.4357 - val_loss: 2.1789 - val_acc: 0.2467\n",
            "Epoch 931/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.3967 - acc: 0.4329 - val_loss: 2.1803 - val_acc: 0.2467\n",
            "Epoch 932/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1716 - val_acc: 0.2500\n",
            "Epoch 933/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1818 - val_acc: 0.2467\n",
            "Epoch 934/1000\n",
            "700/700 [==============================] - 0s 445us/step - loss: 1.3958 - acc: 0.4414 - val_loss: 2.1874 - val_acc: 0.2500\n",
            "Epoch 935/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.3966 - acc: 0.4414 - val_loss: 2.1846 - val_acc: 0.2500\n",
            "Epoch 936/1000\n",
            "700/700 [==============================] - 0s 426us/step - loss: 1.3965 - acc: 0.4429 - val_loss: 2.1883 - val_acc: 0.2500\n",
            "Epoch 937/1000\n",
            "700/700 [==============================] - 0s 461us/step - loss: 1.3960 - acc: 0.4400 - val_loss: 2.1831 - val_acc: 0.2367\n",
            "Epoch 938/1000\n",
            "700/700 [==============================] - 0s 474us/step - loss: 1.3953 - acc: 0.4443 - val_loss: 2.1899 - val_acc: 0.2500\n",
            "Epoch 939/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2500\n",
            "Epoch 940/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1790 - val_acc: 0.2400\n",
            "Epoch 941/1000\n",
            "700/700 [==============================] - 0s 453us/step - loss: 1.3957 - acc: 0.4343 - val_loss: 2.1841 - val_acc: 0.2400\n",
            "Epoch 942/1000\n",
            "700/700 [==============================] - 0s 468us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1692 - val_acc: 0.2333\n",
            "Epoch 943/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1922 - val_acc: 0.2433\n",
            "Epoch 944/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.3944 - acc: 0.4371 - val_loss: 2.1942 - val_acc: 0.2433\n",
            "Epoch 945/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2500\n",
            "Epoch 946/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1833 - val_acc: 0.2467\n",
            "Epoch 947/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1935 - val_acc: 0.2533\n",
            "Epoch 948/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.3940 - acc: 0.4300 - val_loss: 2.1744 - val_acc: 0.2367\n",
            "Epoch 949/1000\n",
            "700/700 [==============================] - 0s 449us/step - loss: 1.3938 - acc: 0.4471 - val_loss: 2.1834 - val_acc: 0.2400\n",
            "Epoch 950/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2367\n",
            "Epoch 951/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
            "Epoch 952/1000\n",
            "700/700 [==============================] - 0s 418us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1852 - val_acc: 0.2467\n",
            "Epoch 953/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.3935 - acc: 0.4371 - val_loss: 2.1988 - val_acc: 0.2533\n",
            "Epoch 954/1000\n",
            "700/700 [==============================] - 0s 424us/step - loss: 1.3940 - acc: 0.4471 - val_loss: 2.1858 - val_acc: 0.2567\n",
            "Epoch 955/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.3936 - acc: 0.4429 - val_loss: 2.1951 - val_acc: 0.2500\n",
            "Epoch 956/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.2024 - val_acc: 0.2433\n",
            "Epoch 957/1000\n",
            "700/700 [==============================] - 0s 422us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2433\n",
            "Epoch 958/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2130 - val_acc: 0.2467\n",
            "Epoch 959/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.3936 - acc: 0.4414 - val_loss: 2.1808 - val_acc: 0.2467\n",
            "Epoch 960/1000\n",
            "700/700 [==============================] - 0s 442us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1918 - val_acc: 0.2467\n",
            "Epoch 961/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1688 - val_acc: 0.2467\n",
            "Epoch 962/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.3931 - acc: 0.4400 - val_loss: 2.1895 - val_acc: 0.2467\n",
            "Epoch 963/1000\n",
            "700/700 [==============================] - 0s 428us/step - loss: 1.3926 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2500\n",
            "Epoch 964/1000\n",
            "700/700 [==============================] - 0s 437us/step - loss: 1.3919 - acc: 0.4357 - val_loss: 2.1782 - val_acc: 0.2433\n",
            "Epoch 965/1000\n",
            "700/700 [==============================] - 0s 431us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1849 - val_acc: 0.2533\n",
            "Epoch 966/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1969 - val_acc: 0.2567\n",
            "Epoch 967/1000\n",
            "700/700 [==============================] - 0s 415us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1947 - val_acc: 0.2467\n",
            "Epoch 968/1000\n",
            "700/700 [==============================] - 0s 413us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1865 - val_acc: 0.2433\n",
            "Epoch 969/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.3917 - acc: 0.4414 - val_loss: 2.1907 - val_acc: 0.2433\n",
            "Epoch 970/1000\n",
            "700/700 [==============================] - 0s 440us/step - loss: 1.3916 - acc: 0.4400 - val_loss: 2.2006 - val_acc: 0.2400\n",
            "Epoch 971/1000\n",
            "700/700 [==============================] - 0s 450us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2467\n",
            "Epoch 972/1000\n",
            "700/700 [==============================] - 0s 404us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.2011 - val_acc: 0.2333\n",
            "Epoch 973/1000\n",
            "700/700 [==============================] - 0s 392us/step - loss: 1.3901 - acc: 0.4400 - val_loss: 2.1959 - val_acc: 0.2500\n",
            "Epoch 974/1000\n",
            "700/700 [==============================] - 0s 409us/step - loss: 1.3908 - acc: 0.4386 - val_loss: 2.1971 - val_acc: 0.2500\n",
            "Epoch 975/1000\n",
            "700/700 [==============================] - 0s 457us/step - loss: 1.3907 - acc: 0.4443 - val_loss: 2.2058 - val_acc: 0.2500\n",
            "Epoch 976/1000\n",
            "700/700 [==============================] - 0s 463us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2500\n",
            "Epoch 977/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.3905 - acc: 0.4343 - val_loss: 2.1915 - val_acc: 0.2400\n",
            "Epoch 978/1000\n",
            "700/700 [==============================] - 0s 474us/step - loss: 1.3904 - acc: 0.4486 - val_loss: 2.1936 - val_acc: 0.2533\n",
            "Epoch 979/1000\n",
            "700/700 [==============================] - 0s 439us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2467\n",
            "Epoch 980/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
            "Epoch 981/1000\n",
            "700/700 [==============================] - 0s 466us/step - loss: 1.3894 - acc: 0.4371 - val_loss: 2.2124 - val_acc: 0.2500\n",
            "Epoch 982/1000\n",
            "700/700 [==============================] - 0s 451us/step - loss: 1.3902 - acc: 0.4400 - val_loss: 2.1965 - val_acc: 0.2533\n",
            "Epoch 983/1000\n",
            "700/700 [==============================] - 0s 467us/step - loss: 1.3897 - acc: 0.4357 - val_loss: 2.2004 - val_acc: 0.2500\n",
            "Epoch 984/1000\n",
            "700/700 [==============================] - 0s 476us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
            "Epoch 985/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.3891 - acc: 0.4400 - val_loss: 2.2033 - val_acc: 0.2367\n",
            "Epoch 986/1000\n",
            "700/700 [==============================] - 0s 472us/step - loss: 1.3891 - acc: 0.4414 - val_loss: 2.2010 - val_acc: 0.2500\n",
            "Epoch 987/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.3887 - acc: 0.4414 - val_loss: 2.1880 - val_acc: 0.2400\n",
            "Epoch 988/1000\n",
            "700/700 [==============================] - 0s 483us/step - loss: 1.3886 - acc: 0.4429 - val_loss: 2.2116 - val_acc: 0.2633\n",
            "Epoch 989/1000\n",
            "700/700 [==============================] - 0s 475us/step - loss: 1.3903 - acc: 0.4357 - val_loss: 2.2104 - val_acc: 0.2533\n",
            "Epoch 990/1000\n",
            "700/700 [==============================] - 0s 473us/step - loss: 1.3887 - acc: 0.4443 - val_loss: 2.2221 - val_acc: 0.2533\n",
            "Epoch 991/1000\n",
            "700/700 [==============================] - 0s 479us/step - loss: 1.3890 - acc: 0.4471 - val_loss: 2.1938 - val_acc: 0.2433\n",
            "Epoch 992/1000\n",
            "700/700 [==============================] - 0s 469us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2048 - val_acc: 0.2400\n",
            "Epoch 993/1000\n",
            "700/700 [==============================] - 0s 458us/step - loss: 1.3885 - acc: 0.4457 - val_loss: 2.2089 - val_acc: 0.2533\n",
            "Epoch 994/1000\n",
            "700/700 [==============================] - 0s 485us/step - loss: 1.3885 - acc: 0.4357 - val_loss: 2.1919 - val_acc: 0.2367\n",
            "Epoch 995/1000\n",
            "700/700 [==============================] - 0s 460us/step - loss: 1.3890 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
            "Epoch 996/1000\n",
            "700/700 [==============================] - 0s 471us/step - loss: 1.3877 - acc: 0.4457 - val_loss: 2.2035 - val_acc: 0.2467\n",
            "Epoch 997/1000\n",
            "700/700 [==============================] - 0s 489us/step - loss: 1.3879 - acc: 0.4429 - val_loss: 2.2026 - val_acc: 0.2533\n",
            "Epoch 998/1000\n",
            "700/700 [==============================] - 0s 452us/step - loss: 1.3887 - acc: 0.4386 - val_loss: 2.2113 - val_acc: 0.2533\n",
            "Epoch 999/1000\n",
            "700/700 [==============================] - 0s 438us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2500\n",
            "Epoch 1000/1000\n",
            "700/700 [==============================] - 0s 475us/step - loss: 1.3879 - acc: 0.4386 - val_loss: 2.2080 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e4972f748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "Pqz9kKylO20V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "37cfb21f-c5f6-4893-d2c2-6b49cc6a91c2"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(8, input_dim=4, init='uniform', activation='relu'))\n",
        "model.add(Dense(6, init='uniform', activation='relu'))\n",
        "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=4, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"294pt\" viewBox=\"0.00 0.00 252.00 294.00\" width=\"252pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 290)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-290 248,-290 248,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139699717266176 -->\n<g class=\"node\" id=\"node1\">\n<title>139699717266176</title>\n<polygon fill=\"none\" points=\".5,-166.5 .5,-212.5 243.5,-212.5 243.5,-166.5 .5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"57\" y=\"-185.8\">dense_11: Dense</text>\n<polyline fill=\"none\" points=\"113.5,-166.5 113.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"113.5,-189.5 171.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"171.5,-166.5 171.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"207.5\" y=\"-197.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"171.5,-189.5 243.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"207.5\" y=\"-174.3\">(None, 8)</text>\n</g>\n<!-- 139699717266400 -->\n<g class=\"node\" id=\"node2\">\n<title>139699717266400</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 244,-129.5 244,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"57\" y=\"-102.8\">dense_12: Dense</text>\n<polyline fill=\"none\" points=\"114,-83.5 114,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"114,-106.5 172,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"172,-83.5 172,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-114.3\">(None, 8)</text>\n<polyline fill=\"none\" points=\"172,-106.5 244,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-91.3\">(None, 6)</text>\n</g>\n<!-- 139699717266176&#45;&gt;139699717266400 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139699717266176-&gt;139699717266400</title>\n<path d=\"M122,-166.3799C122,-158.1745 122,-148.7679 122,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"125.5001,-139.784 122,-129.784 118.5001,-139.784 125.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139699717266680 -->\n<g class=\"node\" id=\"node3\">\n<title>139699717266680</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 244,-46.5 244,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"57\" y=\"-19.8\">dense_13: Dense</text>\n<polyline fill=\"none\" points=\"114,-.5 114,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"114,-23.5 172,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"172,-.5 172,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-31.3\">(None, 6)</text>\n<polyline fill=\"none\" points=\"172,-23.5 244,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139699717266400&#45;&gt;139699717266680 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139699717266400-&gt;139699717266680</title>\n<path d=\"M122,-83.3799C122,-75.1745 122,-65.7679 122,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"125.5001,-56.784 122,-46.784 118.5001,-56.784 125.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139699717266512 -->\n<g class=\"node\" id=\"node4\">\n<title>139699717266512</title>\n<polygon fill=\"none\" points=\"57.5,-249.5 57.5,-285.5 186.5,-285.5 186.5,-249.5 57.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-263.8\">139699717266512</text>\n</g>\n<!-- 139699717266512&#45;&gt;139699717266176 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139699717266512-&gt;139699717266176</title>\n<path d=\"M122,-249.4092C122,-241.4308 122,-231.795 122,-222.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"125.5001,-222.5333 122,-212.5333 118.5001,-222.5334 125.5001,-222.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "motOWp1oROXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amUyUOJ1RPaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "import pydot"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}